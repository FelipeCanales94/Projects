{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from collections import Counter\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(dataframe):\n",
    "\n",
    "    df = dataframe.sample(frac=1)    # Randomize data\n",
    "\n",
    "    # split data into 2 sets -> Training Set (80% of total data), Test Set (20 % of total data)\n",
    "\n",
    "    num_rows = df.shape[0]      # Get total number of rows\n",
    "    total_splitter = int(num_rows * .20)    # Get 20% of total number of rows\n",
    "\n",
    "    total_test, total_train = df[:total_splitter], df[total_splitter:]\n",
    "\n",
    "    # Set features and labels for each set and convert to np arrays\n",
    "\n",
    "    X_train = total_train.iloc[:, :-1].rename_axis('ID').values\n",
    "    y_train = total_train.iloc[:, 30:].rename_axis('ID').values\n",
    "\n",
    "    X_test = total_test.iloc[:, :-1].rename_axis('ID').values\n",
    "    y_test = total_test.iloc[:, 30:].rename_axis('ID').values\n",
    "\n",
    "\n",
    "    return X_train, y_train.flatten(), X_test, y_test.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('project3_dataset1.txt', delimiter='\\s+', header=None)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values\n",
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('project3_dataset2.txt', delimiter='\\s+', header=None)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values\n",
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formula\n",
    "def euclideanDistance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "\n",
    "class KNN:\n",
    "\n",
    "    def __init__(self, k=4):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_predict = [self.helper(x) for x in X]\n",
    "        \n",
    "        return np.array(y_predict)\n",
    "\n",
    "    # calc distance, sort, grab k neighbors, return the most frequent label\n",
    "    def helper(self, x):\n",
    "        all_distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        k_index = np.argsort(distances)[:self.k]\n",
    "        kn_labels = [self.y_train[i] for i in k_index]  \n",
    "        frequent = Counter(kn_labels).most_common(1)\n",
    "        \n",
    "        return frequent[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_feat = X.shape\n",
    "        self.classes = np.unique(y)\n",
    "        num_classes = len(self.classes)\n",
    "        \n",
    "        # get mean, variance and prior probabilities\n",
    "        self.mean = np.zeros((num_classes, num_feat), dtype=np.float64)\n",
    "        self.variance = np.zeros((num_classes, num_feat), dtype=np.float64)\n",
    "        self.priors =  np.zeros(num_classes, dtype=np.float64)\n",
    "        \n",
    "        # calc the above \n",
    "        for index, cl in enumerate(self.classes):\n",
    "            X_cl = X[y==cl]\n",
    "            self.mean[index, :] = X_cl.mean(axis=0)\n",
    "            self.variance[index, :] = X_cl.var(axis=0)\n",
    "            self.priors[index] = X_cl.shape[0] / float(num_samples)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_predict = [self.helper(x) for x in X]\n",
    "        return np.array(y_predict)\n",
    "\n",
    "    # calc posterior prob, class conditional prob, and prior prob\n",
    "    def helper(self, x):\n",
    "        all_post = []\n",
    "        \n",
    "        # used formula in report to calculate these\n",
    "        for index, cl in enumerate(self.classes):\n",
    "            prior = np.log(self.priors[index])\n",
    "            posterior = np.sum(np.log(self.prob_dense(index, x)))\n",
    "            posterior = prior + posterior\n",
    "            all_post.append(posterior)\n",
    "            \n",
    "\n",
    "        return self.classes[np.argmax(all_post)]\n",
    "            \n",
    "\n",
    "    # used formula in report\n",
    "    def prob_dense(self, index, x):\n",
    "        mean = self.mean[index]\n",
    "        variance = self.variance[index]\n",
    "        density = (np.exp(- (x-mean)**2 / (2 * variance)))/(np.sqrt(2 * np.pi * variance))\n",
    "        \n",
    "        return density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula used in report\n",
    "def entropy(y):\n",
    "    count = np.bincount(y)\n",
    "    prob = count / len(y)\n",
    "    return -np.sum([p * np.log2(p) for p in prob if p > 0])\n",
    "\n",
    "# Basic Node class\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, feat=None, thresh=None, left=None, right=None, *, val=None):\n",
    "        self.feat = feat\n",
    "        self.thresh = thresh\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.val = val\n",
    "\n",
    "    def leaf(self):\n",
    "        return self.val is not None\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, min_split=2, maxdepth=100, num_feats=None):\n",
    "        self.min_split = min_split\n",
    "        self.maxdepth = maxdepth\n",
    "        self.num_feats = num_feats\n",
    "        self.root = None\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.num_feats = X.shape[1] if not self.num_feats else min(self.num_feats, X.shape[1])\n",
    "        self.root = self.grow(X, y)\n",
    "\n",
    "    # make prediction\n",
    "    def predict(self, X):\n",
    "        return np.array([self.traverse(x, self.root) for x in X])\n",
    "\n",
    "    # grows tree\n",
    "    def grow(self, X, y, depth=0):\n",
    "        num_sample, num_feat = X.shape\n",
    "        num_label = len(np.unique(y))\n",
    "\n",
    "        if (depth >= self.maxdepth\n",
    "                or num_label == 1\n",
    "                or num_sample < self.min_split):\n",
    "            val_leaf = self.frequent(y)\n",
    "            return Node(val=val_leaf)\n",
    "\n",
    "        index_feats = np.random.choice(num_feat, self.num_feats, replace=False)\n",
    "\n",
    "        greedy_feat, greedy_threshold = self.greediness(X, y, index_feats)\n",
    "        \n",
    "        left_sibs, right_sibs = self.splitter(X[:, greedy_feat], greedy_threshold)\n",
    "        left_node = self.grow(X[left_sibs, :], y[left_sibs], depth+1)\n",
    "        right_node = self.grow(X[right_sibs, :], y[right_sibs], depth+1)\n",
    "        return Node(greedy_feat, greedy_threshold, left_node, right_node)\n",
    "\n",
    "    # gets best gain\n",
    "    def greediness(self, X, y, index_feats):\n",
    "        current_best = -1\n",
    "        index_splitter, threshold_splitter = None, None\n",
    "        for index_feat in index_feats:\n",
    "            X_column = X[:, index_feats]\n",
    "            threshes = np.unique(X_column)\n",
    "            for thresh in threshes:\n",
    "                gain = self.gain(y, X_column, thresh)\n",
    "\n",
    "                if gain > current_best:\n",
    "                    current_best = gain\n",
    "                    index_splitter = index_feats\n",
    "                    threshold_splitter = thresh\n",
    "\n",
    "        return index_splitter, threshold_splitter\n",
    "\n",
    "    # calculates gain -> entropy of parent - weighted avg * entropy of child\n",
    "    def gain(self, y, X_column, threshold_splitter):\n",
    "        e_parent = entropy(y)\n",
    "        left_child, right_child = self.splitter(X_column, threshold_splitter)\n",
    "        if len(left_child) == 0 or len(right_child) == 0:\n",
    "            return 0\n",
    "\n",
    "        label_length = len(y)\n",
    "        left_length, right_length = len(left_child), len(right_child)\n",
    "        left_entropy, right_entropy = entropy(y[left_child]), entropy(y[right_child])\n",
    "        e_children = (left_length / label_length) * left_entropy + (right_length / label_length) * right_entropy\n",
    "\n",
    "        gain = e_parent - e_children\n",
    "        return gain\n",
    "\n",
    "    # returns all left children and right children\n",
    "    def splitter(self, X_column, threshold_splitter):\n",
    "        left_sibs = np.argwhere(X_column <= threshold_splitter).flatten()\n",
    "        right_sibs = np.argwhere(X_column > threshold_splitter).flatten()\n",
    "        return left_sibs, right_sibs\n",
    "\n",
    "    # traverses through tree\n",
    "    def traverse(self, x, node):\n",
    "        if node.left():\n",
    "            return node.val\n",
    "\n",
    "        if x[node.feat] <= node.thresh:\n",
    "            return self.traverse(x, node.left)\n",
    "        return self.traverse(x, node.right)\n",
    "\n",
    "    # return the most frequent label\n",
    "    def frequent(self, y):\n",
    "        count = Counter(y)\n",
    "        frequent = count.most_common(1)[0][0]\n",
    "        return frequent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(X, y):\n",
    "    num_sample = X.shape[0]\n",
    "    random_index = np.random.choice(num_sample, num_sample, replace=True)\n",
    "    return X[random_index], y[random_index]\n",
    "\n",
    "def frequent(y):\n",
    "    count = Counter(y)\n",
    "    frequency = count.most_common(1)[0][0]\n",
    "    return frequency\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self, num_trees=10, min_split=2,\n",
    "                 maxdepth=100, num_feats=None):\n",
    "        self.num_trees = num_trees\n",
    "        self.min_split = min_split\n",
    "        self.maxdepth = maxdepth\n",
    "        self.num_feats = num_feats\n",
    "        self.all_trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.all_trees = []\n",
    "        for _ in range(self.num_trees):\n",
    "            single_tree = DecisionTree(min_split=self.min_split,\n",
    "                maxdepth=self.maxdepth, num_feats=self.num_feats)\n",
    "            X_samples, y_samples = bootstrap(X, y)\n",
    "            single_tree.fit(X_samples, y_samples)\n",
    "            self.all_trees.append(single_tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictiona = np.array([single_tree.predict(X) for tree in self.all_trees])\n",
    "        predictiona = np.swapaxes(predictiona, 0, 1)\n",
    "        y_predict = [frequent(predict) for predict in predictiona]\n",
    "        return np.array(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def KFold_CV(n, X, Y, model):\n",
    "    kf = KFold(n_splits=n,shuffle=False)\n",
    "    kf.split(X)    \n",
    "\n",
    "    accuracy_model = []\n",
    "    precision_model = []\n",
    "    recall_model = []\n",
    "    f1_model = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train) \n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy_model.append(accuracy_score(y_test, predictions, normalize=True)*100)\n",
    "        precision_model.append(precision_score(y_test, predictions)*100)\n",
    "        recall_model.append(recall_score(y_test, predictions)*100)\n",
    "        f1_model.append(f1_score(y_test, predictions)*100)\n",
    "        \n",
    "    accuracy = np.mean(accuracy_model)\n",
    "    precision = np.mean(precision_model)\n",
    "    recall = np.mean(recall_model)\n",
    "    f1score = np.mean(f1_model)\n",
    "    \n",
    "    return(accuracy, precision, recall, f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data1.iloc[:,-1:].to_numpy()\n",
    "y = y.flatten()\n",
    "X = data1.drop(data1.columns[30], axis=1).to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "X_train, y_train, X_test, y_test = getData(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE\n",
    "\n",
    "clf = DecisionTree(maxdepth=10)\n",
    "clf.fit(X_train, y_train) \n",
    "predictions = clf.predict(Xtest)\n",
    "print(\"Decision Tree accuracy: \", accuracy_score(y_test, predictions))\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Decision Tree Precision: %f' % precision)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Decision Tree Recall: %f' % recall)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('Decision Tree F1 score: %f' % f1)\n",
    "\n",
    "print('------------K-Fold Cross Validation Result---------------------')\n",
    "clf = DecisionTree(maxdepth=10)\n",
    "kfold_result = KFold_CV(10, X, Y, clf)\n",
    "print(\"Decision Tree accuracy: \", kfold_result[0]) * .001\n",
    "print('Decision Tree Precision: %f' % kfold_result[1])* .001\n",
    "print('Decision Tree Recall: %f' % kfold_result[2])* .001\n",
    "print('Decision Tree F1 score: %f' % kfold_result[3])* .001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "\n",
    "clf = RandomForest(num_trees=5, maxdepth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print('Random Forest accuracy: ', accuracy_score(y_test, predictions))\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Random Forest Precision: %f' % precision)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Random Forest Recall: %f' % recall)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('Random Forest F1 score: %f' % f1)\n",
    "\n",
    "print('------------K-Fold Cross Validation Result---------------------')\n",
    "clf = RandomForest(n_trees=5, max_depth=10)\n",
    "kfold_result = KFold_CV(10, X, Y, clf)\n",
    "print(\"Random Forest accuracy: \", kfold_result[0])\n",
    "print('Random Forest Precision: %f' % kfold_result[1])\n",
    "print('Random Forest Recall: %f' % kfold_result[2])\n",
    "print('Random Forest F1 score: %f' % kfold_result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES\n",
    "nb = NaiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = nb.predict(X_test)\n",
    "print(\"Naive Bayes accuracy: \", accuracy_score(y_test, predictions))\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Naive Bayes Precision: %f' % precision)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Naive Bayes Recall: %f' % recall)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('Naive Bayes F1 score: %f' % f1)\n",
    "\n",
    "print('------------K-Fold Cross Validation Result---------------------')\n",
    "nb = NaiveBayes()\n",
    "kfold_result = KFold_CV(10, X, y, nb)\n",
    "print(\"Naive Bayes accuracy: \", kfold_result[0])\n",
    "print('Naive Bayes Precision: %f' % kfold_result[1])\n",
    "print('Naive Bayes Recall: %f' % kfold_result[2])\n",
    "print('Naive Bayes F1 score: %f' % kfold_result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN \n",
    "\n",
    "clf = KNN(k=5)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"KNN accuracy: \", accuracy_score(y_test, predictions))\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('KNN Precision: %f' % precision)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('KNN Recall: %f' % recall)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('KNN F1 score: %f' % f1)\n",
    "\n",
    "\n",
    "print('------------K-Fold Cross Validation Result---------------------')\n",
    "clf = KNN(k=5)\n",
    "kfold_result = KFold_CV(10, X, y, clf)\n",
    "print(\"KNN accuracy: \", kfold_result[0])\n",
    "print('KNN Precision: %f' % kfold_result[1])\n",
    "print('KNN Recall: %f' % kfold_result[2])\n",
    "print('KNN F1 score: %f' % kfold_result[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "data2[4] = encoder.fit_transform(data2[4])\n",
    "y = data2.iloc[:,-1:].to_numpy()\n",
    "y = y.flatten()\n",
    "X = data2.drop(data2.columns[9], axis=1).to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DECISION TREE\n",
    "\n",
    "clf = DecisionTree(max_depth=10)\n",
    "clf.fit(X_train, y_train) \n",
    "predictions = clf.predict(X_test)\n",
    "print(\"Decision Tree accuracy: \", accuracy_score(y_test, predictions))\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Decision Tree Precision: %f' % precision)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Decision Tree Recall: %f' % recall)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('Decision Tree F1 score: %f' % f1)\n",
    "\n",
    "\n",
    "print('------------K-Fold Cross Validation Result---------------------')\n",
    "clf = DecisionTree(max_depth=10)\n",
    "kfold_result = KFold_CV(10, X, Y, clf)\n",
    "print(\"Decision Tree accuracy: \", kfold_result[0])\n",
    "print('Decision Tree Precision: %f' % kfold_result[1])\n",
    "print('Decision Tree Recall: %f' % kfold_result[2])\n",
    "print('Decision Tree F1 score: %f' % kfold_result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "\n",
    "clf = RandomForest(n_trees=5, max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print('Random Forest accuracy: ', accuracy_score(y_test, predictions))\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Random Forest Precision: %f' % precision)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Random Forest Recall: %f' % recall)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('Random Forest F1 score: %f' % f1)\n",
    "\n",
    "\n",
    "print('------------K-Fold Cross Validation Result---------------------')\n",
    "clf = RandomForest(n_trees=5, max_depth=10)\n",
    "kfold_result = KFold_CV(10, X, Y, clf)\n",
    "print(\"Random Forest accuracy: \", kfold_result[0])\n",
    "print('Random Forest Precision: %f' % kfold_result[1])\n",
    "print('Random Forest Recall: %f' % kfold_result[2])\n",
    "print('Random Forest F1 score: %f' % kfold_result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES\n",
    "nb = NaiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "predictions = nb.predict(X_test)\n",
    "print(\"Naive Bayes accuracy: \", accuracy_score(y_test, predictions))\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('Naive Bayes Precision: %f' % precision)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('Naive Bayes Recall: %f' % recall)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('Naive Bayes F1 score: %f' % f1)\n",
    "\n",
    "print('------------K-Fold Cross Validation Result---------------------')\n",
    "nb = NaiveBayes()\n",
    "kfold_result = KFold_CV(10, X, Y, nb)\n",
    "print(\"Naive Bayes accuracy: \", kfold_result[0])\n",
    "print('Naive Bayes Precision: %f' % kfold_result[1])\n",
    "print('Naive Bayes Recall: %f' % kfold_result[2])\n",
    "print('Naive Bayes F1 score: %f' % kfold_result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN \n",
    "\n",
    "clf = KNN(k=5)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"KNN accuracy: \", accuracy_score(y_test, predictions))\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('KNN Precision: %f' % precision)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('KNN Recall: %f' % recall)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('KNN F1 score: %f' % f1)\n",
    "\n",
    "\n",
    "\n",
    "print('------------K-Fold Cross Validation Result---------------------')\n",
    "clf = KNN(k=5)\n",
    "kfold_result = KFold_CV(10, X, Y, clf)\n",
    "print(\"KNN accuracy: \", kfold_result[0])\n",
    "print('KNN Precision: %f' % kfold_result[1])\n",
    "print('KNN Recall: %f' % kfold_result[2])\n",
    "print('KNN F1 score: %f' % kfold_result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_train = pd.read_csv('project3_dataset3_train.txt', delimiter='\\s+', header=None)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = demo_train.iloc[:,-1:].to_numpy()\n",
    "y = y.flatten()\n",
    "X = demo_train.drop(demo_train.columns[4], axis=1).to_numpy()\n",
    "\n",
    "X_train, y_train = train_test_split(demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_test = pd.read_csv('project3_dataset3_test.txt', delimiter='\\s+', header=None)\n",
    "\n",
    "y1 = demo_test.iloc[:,-1:].to_numpy()\n",
    "y1 = y1.flatten()\n",
    "X1 = demo_test.drop(demo_test.columns[4], axis=1).to_numpy()\n",
    "\n",
    "X_test, y_test = train_test_split(demo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNN(k=3)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"KNN accuracy: \", accuracy_score(y_test, predictions))\n",
    "precision = precision_score(y_test, predictions)\n",
    "print('KNN Precision: %f' % precision)\n",
    "recall = recall_score(y_test, predictions)\n",
    "print('KNN Recall: %f' % recall)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('KNN F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
