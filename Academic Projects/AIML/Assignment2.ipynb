{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "falling-leather",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout, merge, Lambda, Input, Add, Conv1D, LeakyReLU, Flatten, Multiply, Reshape, MaxPooling2D\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-activity",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "emerging-midnight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8)\n"
     ]
    }
   ],
   "source": [
    "data = 'diabetes.csv'\n",
    "\n",
    "df = pd.read_csv(data)\n",
    "df = df.sample(frac=1)    # Randomize data\n",
    "\n",
    "# set up X and y\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:,-1:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "print(X_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "curious-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scale = StandardScaler().fit(X_train)\n",
    "X_train = train_scale.transform(X_train)\n",
    "\n",
    "test_scale = StandardScaler().fit(X_test)\n",
    "X_test = test_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "english-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu')) # input layer\n",
    "model.add(Dense(15, activation='relu')) # hidden layer \n",
    "model.add(Dense(1, activation='sigmoid')) # output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intense-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "healthy-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 491 samples, validate on 123 samples\n",
      "Epoch 1/300\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.6639 - accuracy: 0.6314 - val_loss: 0.6469 - val_accuracy: 0.6667\n",
      "Epoch 2/300\n",
      "491/491 [==============================] - 0s 179us/step - loss: 0.6351 - accuracy: 0.6517 - val_loss: 0.6149 - val_accuracy: 0.6911\n",
      "Epoch 3/300\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.6083 - accuracy: 0.6843 - val_loss: 0.5836 - val_accuracy: 0.6829\n",
      "Epoch 4/300\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.5796 - accuracy: 0.6986 - val_loss: 0.5518 - val_accuracy: 0.7073\n",
      "Epoch 5/300\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.5512 - accuracy: 0.7047 - val_loss: 0.5213 - val_accuracy: 0.7154\n",
      "Epoch 6/300\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.5268 - accuracy: 0.7271 - val_loss: 0.5046 - val_accuracy: 0.7236\n",
      "Epoch 7/300\n",
      "491/491 [==============================] - 0s 189us/step - loss: 0.5087 - accuracy: 0.7373 - val_loss: 0.4874 - val_accuracy: 0.7398\n",
      "Epoch 8/300\n",
      "491/491 [==============================] - 0s 198us/step - loss: 0.4968 - accuracy: 0.7475 - val_loss: 0.4743 - val_accuracy: 0.7480\n",
      "Epoch 9/300\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4869 - accuracy: 0.7434 - val_loss: 0.4641 - val_accuracy: 0.7642\n",
      "Epoch 10/300\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.4802 - accuracy: 0.7597 - val_loss: 0.4588 - val_accuracy: 0.7561\n",
      "Epoch 11/300\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.4724 - accuracy: 0.7617 - val_loss: 0.4561 - val_accuracy: 0.7724\n",
      "Epoch 12/300\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4669 - accuracy: 0.7678 - val_loss: 0.4521 - val_accuracy: 0.7886\n",
      "Epoch 13/300\n",
      "491/491 [==============================] - 0s 186us/step - loss: 0.4632 - accuracy: 0.7617 - val_loss: 0.4503 - val_accuracy: 0.7886\n",
      "Epoch 14/300\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4612 - accuracy: 0.7739 - val_loss: 0.4520 - val_accuracy: 0.7886\n",
      "Epoch 15/300\n",
      "491/491 [==============================] - 0s 192us/step - loss: 0.4570 - accuracy: 0.7678 - val_loss: 0.4482 - val_accuracy: 0.7805\n",
      "Epoch 16/300\n",
      "491/491 [==============================] - 0s 195us/step - loss: 0.4548 - accuracy: 0.7800 - val_loss: 0.4482 - val_accuracy: 0.7805\n",
      "Epoch 17/300\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.4515 - accuracy: 0.7719 - val_loss: 0.4503 - val_accuracy: 0.7805\n",
      "Epoch 18/300\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4498 - accuracy: 0.7760 - val_loss: 0.4469 - val_accuracy: 0.7724\n",
      "Epoch 19/300\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4474 - accuracy: 0.7760 - val_loss: 0.4526 - val_accuracy: 0.7805\n",
      "Epoch 20/300\n",
      "491/491 [==============================] - 0s 181us/step - loss: 0.4452 - accuracy: 0.7800 - val_loss: 0.4513 - val_accuracy: 0.7805\n",
      "Epoch 21/300\n",
      "491/491 [==============================] - 0s 200us/step - loss: 0.4449 - accuracy: 0.7780 - val_loss: 0.4514 - val_accuracy: 0.7805\n",
      "Epoch 22/300\n",
      "491/491 [==============================] - 0s 188us/step - loss: 0.4422 - accuracy: 0.7760 - val_loss: 0.4473 - val_accuracy: 0.7724\n",
      "Epoch 23/300\n",
      "491/491 [==============================] - 0s 193us/step - loss: 0.4402 - accuracy: 0.7841 - val_loss: 0.4517 - val_accuracy: 0.7805\n",
      "Epoch 24/300\n",
      "491/491 [==============================] - 0s 206us/step - loss: 0.4387 - accuracy: 0.7800 - val_loss: 0.4466 - val_accuracy: 0.7805\n",
      "Epoch 25/300\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4383 - accuracy: 0.7760 - val_loss: 0.4472 - val_accuracy: 0.7805\n",
      "Epoch 26/300\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.4353 - accuracy: 0.7821 - val_loss: 0.4510 - val_accuracy: 0.7886\n",
      "Epoch 27/300\n",
      "491/491 [==============================] - 0s 198us/step - loss: 0.4343 - accuracy: 0.7841 - val_loss: 0.4493 - val_accuracy: 0.7805\n",
      "Epoch 28/300\n",
      "491/491 [==============================] - 0s 198us/step - loss: 0.4321 - accuracy: 0.7780 - val_loss: 0.4516 - val_accuracy: 0.7805\n",
      "Epoch 29/300\n",
      "491/491 [==============================] - 0s 185us/step - loss: 0.4316 - accuracy: 0.7862 - val_loss: 0.4476 - val_accuracy: 0.7805\n",
      "Epoch 30/300\n",
      "491/491 [==============================] - 0s 183us/step - loss: 0.4298 - accuracy: 0.7780 - val_loss: 0.4491 - val_accuracy: 0.7967\n",
      "Epoch 31/300\n",
      "491/491 [==============================] - 0s 204us/step - loss: 0.4286 - accuracy: 0.7800 - val_loss: 0.4529 - val_accuracy: 0.7967\n",
      "Epoch 32/300\n",
      "491/491 [==============================] - 0s 221us/step - loss: 0.4273 - accuracy: 0.7780 - val_loss: 0.4553 - val_accuracy: 0.8049\n",
      "Epoch 33/300\n",
      "491/491 [==============================] - 0s 223us/step - loss: 0.4252 - accuracy: 0.7821 - val_loss: 0.4526 - val_accuracy: 0.7886\n",
      "Epoch 34/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.4256 - accuracy: 0.7821 - val_loss: 0.4540 - val_accuracy: 0.7886\n",
      "Epoch 35/300\n",
      "491/491 [==============================] - 0s 149us/step - loss: 0.4245 - accuracy: 0.7800 - val_loss: 0.4518 - val_accuracy: 0.7805\n",
      "Epoch 36/300\n",
      "491/491 [==============================] - 0s 216us/step - loss: 0.4221 - accuracy: 0.7862 - val_loss: 0.4528 - val_accuracy: 0.7967\n",
      "Epoch 37/300\n",
      "491/491 [==============================] - 0s 194us/step - loss: 0.4211 - accuracy: 0.7800 - val_loss: 0.4574 - val_accuracy: 0.7967\n",
      "Epoch 38/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.4196 - accuracy: 0.7882 - val_loss: 0.4589 - val_accuracy: 0.7967\n",
      "Epoch 39/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.4191 - accuracy: 0.7882 - val_loss: 0.4590 - val_accuracy: 0.7886\n",
      "Epoch 40/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.4173 - accuracy: 0.7800 - val_loss: 0.4597 - val_accuracy: 0.7886\n",
      "Epoch 41/300\n",
      "491/491 [==============================] - 0s 150us/step - loss: 0.4166 - accuracy: 0.7902 - val_loss: 0.4643 - val_accuracy: 0.8049\n",
      "Epoch 42/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.4148 - accuracy: 0.7902 - val_loss: 0.4608 - val_accuracy: 0.7967\n",
      "Epoch 43/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.4143 - accuracy: 0.7902 - val_loss: 0.4599 - val_accuracy: 0.7967\n",
      "Epoch 44/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.4138 - accuracy: 0.7963 - val_loss: 0.4662 - val_accuracy: 0.7967\n",
      "Epoch 45/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.4134 - accuracy: 0.7780 - val_loss: 0.4507 - val_accuracy: 0.8049\n",
      "Epoch 46/300\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4121 - accuracy: 0.7943 - val_loss: 0.4584 - val_accuracy: 0.7967\n",
      "Epoch 47/300\n",
      "491/491 [==============================] - 0s 213us/step - loss: 0.4112 - accuracy: 0.7963 - val_loss: 0.4598 - val_accuracy: 0.7886\n",
      "Epoch 48/300\n",
      "491/491 [==============================] - 0s 227us/step - loss: 0.4105 - accuracy: 0.7984 - val_loss: 0.4599 - val_accuracy: 0.7805\n",
      "Epoch 49/300\n",
      "491/491 [==============================] - 0s 244us/step - loss: 0.4074 - accuracy: 0.7943 - val_loss: 0.4624 - val_accuracy: 0.7886\n",
      "Epoch 50/300\n",
      "491/491 [==============================] - 0s 190us/step - loss: 0.4068 - accuracy: 0.8045 - val_loss: 0.4657 - val_accuracy: 0.7805\n",
      "Epoch 51/300\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4065 - accuracy: 0.8004 - val_loss: 0.4664 - val_accuracy: 0.7805\n",
      "Epoch 52/300\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4047 - accuracy: 0.7984 - val_loss: 0.4672 - val_accuracy: 0.7805\n",
      "Epoch 53/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.4035 - accuracy: 0.7943 - val_loss: 0.4685 - val_accuracy: 0.7886\n",
      "Epoch 54/300\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.4037 - accuracy: 0.8004 - val_loss: 0.4691 - val_accuracy: 0.7724\n",
      "Epoch 55/300\n",
      "491/491 [==============================] - 0s 180us/step - loss: 0.4012 - accuracy: 0.8086 - val_loss: 0.4660 - val_accuracy: 0.7886\n",
      "Epoch 56/300\n",
      "491/491 [==============================] - 0s 207us/step - loss: 0.4010 - accuracy: 0.8106 - val_loss: 0.4681 - val_accuracy: 0.7967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.3994 - accuracy: 0.8045 - val_loss: 0.4682 - val_accuracy: 0.7886\n",
      "Epoch 58/300\n",
      "491/491 [==============================] - 0s 185us/step - loss: 0.3989 - accuracy: 0.7963 - val_loss: 0.4695 - val_accuracy: 0.7967\n",
      "Epoch 59/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3986 - accuracy: 0.8004 - val_loss: 0.4705 - val_accuracy: 0.7967\n",
      "Epoch 60/300\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.3978 - accuracy: 0.7984 - val_loss: 0.4704 - val_accuracy: 0.7967\n",
      "Epoch 61/300\n",
      "491/491 [==============================] - 0s 216us/step - loss: 0.3987 - accuracy: 0.8187 - val_loss: 0.4679 - val_accuracy: 0.7967\n",
      "Epoch 62/300\n",
      "491/491 [==============================] - 0s 233us/step - loss: 0.3958 - accuracy: 0.8045 - val_loss: 0.4660 - val_accuracy: 0.7886\n",
      "Epoch 63/300\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.3958 - accuracy: 0.7984 - val_loss: 0.4620 - val_accuracy: 0.7886\n",
      "Epoch 64/300\n",
      "491/491 [==============================] - 0s 218us/step - loss: 0.3965 - accuracy: 0.7923 - val_loss: 0.4687 - val_accuracy: 0.7967\n",
      "Epoch 65/300\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.3957 - accuracy: 0.8045 - val_loss: 0.4663 - val_accuracy: 0.7967\n",
      "Epoch 66/300\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.3932 - accuracy: 0.8126 - val_loss: 0.4752 - val_accuracy: 0.7886\n",
      "Epoch 67/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3926 - accuracy: 0.8065 - val_loss: 0.4746 - val_accuracy: 0.7886\n",
      "Epoch 68/300\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.3914 - accuracy: 0.8126 - val_loss: 0.4744 - val_accuracy: 0.7886\n",
      "Epoch 69/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3898 - accuracy: 0.8004 - val_loss: 0.4746 - val_accuracy: 0.7886\n",
      "Epoch 70/300\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.3898 - accuracy: 0.7963 - val_loss: 0.4748 - val_accuracy: 0.7967\n",
      "Epoch 71/300\n",
      "491/491 [==============================] - 0s 194us/step - loss: 0.3892 - accuracy: 0.8065 - val_loss: 0.4678 - val_accuracy: 0.7967\n",
      "Epoch 72/300\n",
      "491/491 [==============================] - 0s 209us/step - loss: 0.3898 - accuracy: 0.8065 - val_loss: 0.4633 - val_accuracy: 0.7886\n",
      "Epoch 73/300\n",
      "491/491 [==============================] - 0s 209us/step - loss: 0.3885 - accuracy: 0.8086 - val_loss: 0.4687 - val_accuracy: 0.7886\n",
      "Epoch 74/300\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.3869 - accuracy: 0.8045 - val_loss: 0.4661 - val_accuracy: 0.7886\n",
      "Epoch 75/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3874 - accuracy: 0.8065 - val_loss: 0.4747 - val_accuracy: 0.7967\n",
      "Epoch 76/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.3863 - accuracy: 0.8086 - val_loss: 0.4744 - val_accuracy: 0.7967\n",
      "Epoch 77/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.3859 - accuracy: 0.8045 - val_loss: 0.4709 - val_accuracy: 0.7967\n",
      "Epoch 78/300\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.3851 - accuracy: 0.8086 - val_loss: 0.4784 - val_accuracy: 0.7967\n",
      "Epoch 79/300\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.3841 - accuracy: 0.8126 - val_loss: 0.4782 - val_accuracy: 0.7967\n",
      "Epoch 80/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.3820 - accuracy: 0.8024 - val_loss: 0.4758 - val_accuracy: 0.7967\n",
      "Epoch 81/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.3815 - accuracy: 0.8024 - val_loss: 0.4808 - val_accuracy: 0.7967\n",
      "Epoch 82/300\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.3809 - accuracy: 0.8086 - val_loss: 0.4784 - val_accuracy: 0.7967\n",
      "Epoch 83/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3801 - accuracy: 0.8126 - val_loss: 0.4813 - val_accuracy: 0.7967\n",
      "Epoch 84/300\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.3794 - accuracy: 0.8187 - val_loss: 0.4799 - val_accuracy: 0.7967\n",
      "Epoch 85/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3793 - accuracy: 0.8106 - val_loss: 0.4869 - val_accuracy: 0.7967\n",
      "Epoch 86/300\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.3788 - accuracy: 0.8065 - val_loss: 0.4776 - val_accuracy: 0.7886\n",
      "Epoch 87/300\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.3764 - accuracy: 0.8086 - val_loss: 0.4841 - val_accuracy: 0.7967\n",
      "Epoch 88/300\n",
      "491/491 [==============================] - 0s 151us/step - loss: 0.3759 - accuracy: 0.8065 - val_loss: 0.4827 - val_accuracy: 0.7967\n",
      "Epoch 89/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3749 - accuracy: 0.8126 - val_loss: 0.4854 - val_accuracy: 0.7967\n",
      "Epoch 90/300\n",
      "491/491 [==============================] - 0s 192us/step - loss: 0.3755 - accuracy: 0.8126 - val_loss: 0.4902 - val_accuracy: 0.7967\n",
      "Epoch 91/300\n",
      "491/491 [==============================] - 0s 212us/step - loss: 0.3741 - accuracy: 0.8167 - val_loss: 0.4829 - val_accuracy: 0.7967\n",
      "Epoch 92/300\n",
      "491/491 [==============================] - 0s 201us/step - loss: 0.3734 - accuracy: 0.8147 - val_loss: 0.4937 - val_accuracy: 0.8049\n",
      "Epoch 93/300\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.3735 - accuracy: 0.8167 - val_loss: 0.4971 - val_accuracy: 0.7805\n",
      "Epoch 94/300\n",
      "491/491 [==============================] - 0s 200us/step - loss: 0.3717 - accuracy: 0.8147 - val_loss: 0.4919 - val_accuracy: 0.7967\n",
      "Epoch 95/300\n",
      "491/491 [==============================] - 0s 185us/step - loss: 0.3710 - accuracy: 0.8147 - val_loss: 0.4927 - val_accuracy: 0.7967\n",
      "Epoch 96/300\n",
      "491/491 [==============================] - 0s 180us/step - loss: 0.3711 - accuracy: 0.8187 - val_loss: 0.4987 - val_accuracy: 0.7805\n",
      "Epoch 97/300\n",
      "491/491 [==============================] - 0s 189us/step - loss: 0.3697 - accuracy: 0.8147 - val_loss: 0.4928 - val_accuracy: 0.7967\n",
      "Epoch 98/300\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.3685 - accuracy: 0.8167 - val_loss: 0.5019 - val_accuracy: 0.7886\n",
      "Epoch 99/300\n",
      "491/491 [==============================] - 0s 188us/step - loss: 0.3685 - accuracy: 0.8167 - val_loss: 0.4980 - val_accuracy: 0.7886\n",
      "Epoch 100/300\n",
      "491/491 [==============================] - 0s 195us/step - loss: 0.3667 - accuracy: 0.8126 - val_loss: 0.4975 - val_accuracy: 0.7805\n",
      "Epoch 101/300\n",
      "491/491 [==============================] - 0s 199us/step - loss: 0.3672 - accuracy: 0.8208 - val_loss: 0.4998 - val_accuracy: 0.7886\n",
      "Epoch 102/300\n",
      "491/491 [==============================] - 0s 199us/step - loss: 0.3653 - accuracy: 0.8187 - val_loss: 0.4968 - val_accuracy: 0.7886\n",
      "Epoch 103/300\n",
      "491/491 [==============================] - 0s 205us/step - loss: 0.3649 - accuracy: 0.8269 - val_loss: 0.4903 - val_accuracy: 0.7805\n",
      "Epoch 104/300\n",
      "491/491 [==============================] - 0s 207us/step - loss: 0.3638 - accuracy: 0.8208 - val_loss: 0.4899 - val_accuracy: 0.7805\n",
      "Epoch 105/300\n",
      "491/491 [==============================] - 0s 186us/step - loss: 0.3632 - accuracy: 0.8248 - val_loss: 0.4979 - val_accuracy: 0.7886\n",
      "Epoch 106/300\n",
      "491/491 [==============================] - 0s 187us/step - loss: 0.3609 - accuracy: 0.8289 - val_loss: 0.4953 - val_accuracy: 0.7805\n",
      "Epoch 107/300\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.3611 - accuracy: 0.8228 - val_loss: 0.4930 - val_accuracy: 0.7805\n",
      "Epoch 108/300\n",
      "491/491 [==============================] - 0s 187us/step - loss: 0.3595 - accuracy: 0.8228 - val_loss: 0.4970 - val_accuracy: 0.7967\n",
      "Epoch 109/300\n",
      "491/491 [==============================] - 0s 186us/step - loss: 0.3575 - accuracy: 0.8289 - val_loss: 0.5059 - val_accuracy: 0.7886\n",
      "Epoch 110/300\n",
      "491/491 [==============================] - 0s 185us/step - loss: 0.3564 - accuracy: 0.8248 - val_loss: 0.5053 - val_accuracy: 0.7886\n",
      "Epoch 111/300\n",
      "491/491 [==============================] - 0s 185us/step - loss: 0.3576 - accuracy: 0.8248 - val_loss: 0.4934 - val_accuracy: 0.7886\n",
      "Epoch 112/300\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.3556 - accuracy: 0.8350 - val_loss: 0.4966 - val_accuracy: 0.7886\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 178us/step - loss: 0.3560 - accuracy: 0.8269 - val_loss: 0.5034 - val_accuracy: 0.7886\n",
      "Epoch 114/300\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.3558 - accuracy: 0.8330 - val_loss: 0.4976 - val_accuracy: 0.7886\n",
      "Epoch 115/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.3537 - accuracy: 0.8310 - val_loss: 0.4998 - val_accuracy: 0.7886\n",
      "Epoch 116/300\n",
      "491/491 [==============================] - 0s 195us/step - loss: 0.3535 - accuracy: 0.8289 - val_loss: 0.5033 - val_accuracy: 0.7886\n",
      "Epoch 117/300\n",
      "491/491 [==============================] - 0s 209us/step - loss: 0.3526 - accuracy: 0.8269 - val_loss: 0.5004 - val_accuracy: 0.7886\n",
      "Epoch 118/300\n",
      "491/491 [==============================] - 0s 202us/step - loss: 0.3531 - accuracy: 0.8310 - val_loss: 0.5088 - val_accuracy: 0.7886\n",
      "Epoch 119/300\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.3509 - accuracy: 0.8269 - val_loss: 0.5105 - val_accuracy: 0.7886\n",
      "Epoch 120/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3511 - accuracy: 0.8269 - val_loss: 0.5092 - val_accuracy: 0.7886\n",
      "Epoch 121/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3498 - accuracy: 0.8310 - val_loss: 0.5147 - val_accuracy: 0.7886\n",
      "Epoch 122/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3492 - accuracy: 0.8350 - val_loss: 0.5105 - val_accuracy: 0.7886\n",
      "Epoch 123/300\n",
      "491/491 [==============================] - 0s 150us/step - loss: 0.3493 - accuracy: 0.8289 - val_loss: 0.5140 - val_accuracy: 0.7886\n",
      "Epoch 124/300\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.3488 - accuracy: 0.8248 - val_loss: 0.5221 - val_accuracy: 0.7805\n",
      "Epoch 125/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3476 - accuracy: 0.8269 - val_loss: 0.5103 - val_accuracy: 0.7886\n",
      "Epoch 126/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3480 - accuracy: 0.8248 - val_loss: 0.5168 - val_accuracy: 0.7886\n",
      "Epoch 127/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.3461 - accuracy: 0.8310 - val_loss: 0.5169 - val_accuracy: 0.7886\n",
      "Epoch 128/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3456 - accuracy: 0.8310 - val_loss: 0.5258 - val_accuracy: 0.7886\n",
      "Epoch 129/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.3442 - accuracy: 0.8371 - val_loss: 0.5151 - val_accuracy: 0.7886\n",
      "Epoch 130/300\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.3463 - accuracy: 0.8371 - val_loss: 0.5184 - val_accuracy: 0.7886\n",
      "Epoch 131/300\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.3446 - accuracy: 0.8432 - val_loss: 0.5189 - val_accuracy: 0.7886\n",
      "Epoch 132/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3492 - accuracy: 0.8330 - val_loss: 0.5522 - val_accuracy: 0.7886\n",
      "Epoch 133/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3442 - accuracy: 0.8371 - val_loss: 0.5309 - val_accuracy: 0.7886\n",
      "Epoch 134/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3425 - accuracy: 0.8371 - val_loss: 0.5277 - val_accuracy: 0.7886\n",
      "Epoch 135/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3438 - accuracy: 0.8350 - val_loss: 0.5219 - val_accuracy: 0.7886\n",
      "Epoch 136/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3412 - accuracy: 0.8411 - val_loss: 0.5225 - val_accuracy: 0.7886\n",
      "Epoch 137/300\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.3465 - accuracy: 0.8289 - val_loss: 0.5273 - val_accuracy: 0.7886\n",
      "Epoch 138/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3413 - accuracy: 0.8350 - val_loss: 0.5256 - val_accuracy: 0.7886\n",
      "Epoch 139/300\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.3403 - accuracy: 0.8391 - val_loss: 0.5205 - val_accuracy: 0.7886\n",
      "Epoch 140/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3395 - accuracy: 0.8350 - val_loss: 0.5316 - val_accuracy: 0.7886\n",
      "Epoch 141/300\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.3391 - accuracy: 0.8391 - val_loss: 0.5336 - val_accuracy: 0.7886\n",
      "Epoch 142/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3397 - accuracy: 0.8330 - val_loss: 0.5284 - val_accuracy: 0.7886\n",
      "Epoch 143/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3397 - accuracy: 0.8371 - val_loss: 0.5242 - val_accuracy: 0.7886\n",
      "Epoch 144/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3398 - accuracy: 0.8330 - val_loss: 0.5364 - val_accuracy: 0.7886\n",
      "Epoch 145/300\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.3386 - accuracy: 0.8371 - val_loss: 0.5366 - val_accuracy: 0.7886\n",
      "Epoch 146/300\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.3426 - accuracy: 0.8310 - val_loss: 0.5509 - val_accuracy: 0.7886\n",
      "Epoch 147/300\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.3373 - accuracy: 0.8371 - val_loss: 0.5472 - val_accuracy: 0.7886\n",
      "Epoch 148/300\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.3379 - accuracy: 0.8371 - val_loss: 0.5396 - val_accuracy: 0.7967\n",
      "Epoch 149/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.3367 - accuracy: 0.8371 - val_loss: 0.5401 - val_accuracy: 0.7886\n",
      "Epoch 150/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3368 - accuracy: 0.8432 - val_loss: 0.5370 - val_accuracy: 0.7967\n",
      "Epoch 151/300\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.3363 - accuracy: 0.8330 - val_loss: 0.5396 - val_accuracy: 0.7886\n",
      "Epoch 152/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3375 - accuracy: 0.8371 - val_loss: 0.5331 - val_accuracy: 0.7967\n",
      "Epoch 153/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3358 - accuracy: 0.8371 - val_loss: 0.5422 - val_accuracy: 0.7967\n",
      "Epoch 154/300\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.3355 - accuracy: 0.8391 - val_loss: 0.5431 - val_accuracy: 0.7805\n",
      "Epoch 155/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3347 - accuracy: 0.8391 - val_loss: 0.5493 - val_accuracy: 0.7805\n",
      "Epoch 156/300\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.3348 - accuracy: 0.8411 - val_loss: 0.5430 - val_accuracy: 0.7886\n",
      "Epoch 157/300\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.3342 - accuracy: 0.8371 - val_loss: 0.5489 - val_accuracy: 0.7886\n",
      "Epoch 158/300\n",
      "491/491 [==============================] - 0s 151us/step - loss: 0.3332 - accuracy: 0.8391 - val_loss: 0.5477 - val_accuracy: 0.7886\n",
      "Epoch 159/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.3337 - accuracy: 0.8350 - val_loss: 0.5424 - val_accuracy: 0.7967\n",
      "Epoch 160/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3322 - accuracy: 0.8411 - val_loss: 0.5439 - val_accuracy: 0.7967\n",
      "Epoch 161/300\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.3332 - accuracy: 0.8371 - val_loss: 0.5460 - val_accuracy: 0.7886\n",
      "Epoch 162/300\n",
      "491/491 [==============================] - 0s 194us/step - loss: 0.3310 - accuracy: 0.8411 - val_loss: 0.5529 - val_accuracy: 0.7967\n",
      "Epoch 163/300\n",
      "491/491 [==============================] - 0s 204us/step - loss: 0.3315 - accuracy: 0.8310 - val_loss: 0.5545 - val_accuracy: 0.7886\n",
      "Epoch 164/300\n",
      "491/491 [==============================] - 0s 183us/step - loss: 0.3309 - accuracy: 0.8391 - val_loss: 0.5525 - val_accuracy: 0.7886\n",
      "Epoch 165/300\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.3312 - accuracy: 0.8411 - val_loss: 0.5561 - val_accuracy: 0.7805\n",
      "Epoch 166/300\n",
      "491/491 [==============================] - 0s 181us/step - loss: 0.3301 - accuracy: 0.8371 - val_loss: 0.5540 - val_accuracy: 0.7805\n",
      "Epoch 167/300\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.3296 - accuracy: 0.8411 - val_loss: 0.5541 - val_accuracy: 0.7805\n",
      "Epoch 168/300\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.3311 - accuracy: 0.8432 - val_loss: 0.5613 - val_accuracy: 0.7805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.3296 - accuracy: 0.8432 - val_loss: 0.5622 - val_accuracy: 0.7886\n",
      "Epoch 170/300\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.3291 - accuracy: 0.8391 - val_loss: 0.5576 - val_accuracy: 0.7724\n",
      "Epoch 171/300\n",
      "491/491 [==============================] - 0s 188us/step - loss: 0.3306 - accuracy: 0.8391 - val_loss: 0.5610 - val_accuracy: 0.7805\n",
      "Epoch 172/300\n",
      "491/491 [==============================] - 0s 179us/step - loss: 0.3282 - accuracy: 0.8452 - val_loss: 0.5564 - val_accuracy: 0.7805\n",
      "Epoch 173/300\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.3296 - accuracy: 0.8432 - val_loss: 0.5632 - val_accuracy: 0.7805\n",
      "Epoch 174/300\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.3286 - accuracy: 0.8432 - val_loss: 0.5643 - val_accuracy: 0.7724\n",
      "Epoch 175/300\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.3289 - accuracy: 0.8391 - val_loss: 0.5600 - val_accuracy: 0.7805\n",
      "Epoch 176/300\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.3273 - accuracy: 0.8371 - val_loss: 0.5676 - val_accuracy: 0.7886\n",
      "Epoch 177/300\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.3278 - accuracy: 0.8371 - val_loss: 0.5596 - val_accuracy: 0.7805\n",
      "Epoch 178/300\n",
      "491/491 [==============================] - 0s 186us/step - loss: 0.3274 - accuracy: 0.8411 - val_loss: 0.5647 - val_accuracy: 0.7886\n",
      "Epoch 179/300\n",
      "491/491 [==============================] - 0s 180us/step - loss: 0.3261 - accuracy: 0.8391 - val_loss: 0.5631 - val_accuracy: 0.7967\n",
      "Epoch 180/300\n",
      "491/491 [==============================] - 0s 190us/step - loss: 0.3269 - accuracy: 0.8411 - val_loss: 0.5637 - val_accuracy: 0.7805\n",
      "Epoch 181/300\n",
      "491/491 [==============================] - 0s 186us/step - loss: 0.3255 - accuracy: 0.8452 - val_loss: 0.5652 - val_accuracy: 0.7805\n",
      "Epoch 182/300\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.3254 - accuracy: 0.8411 - val_loss: 0.5674 - val_accuracy: 0.7805\n",
      "Epoch 183/300\n",
      "491/491 [==============================] - 0s 186us/step - loss: 0.3246 - accuracy: 0.8391 - val_loss: 0.5654 - val_accuracy: 0.7886\n",
      "Epoch 184/300\n",
      "491/491 [==============================] - 0s 194us/step - loss: 0.3238 - accuracy: 0.8411 - val_loss: 0.5690 - val_accuracy: 0.7886\n",
      "Epoch 185/300\n",
      "491/491 [==============================] - 0s 196us/step - loss: 0.3241 - accuracy: 0.8411 - val_loss: 0.5661 - val_accuracy: 0.7805\n",
      "Epoch 186/300\n",
      "491/491 [==============================] - 0s 183us/step - loss: 0.3239 - accuracy: 0.8432 - val_loss: 0.5636 - val_accuracy: 0.7886\n",
      "Epoch 187/300\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.3241 - accuracy: 0.8391 - val_loss: 0.5705 - val_accuracy: 0.7805\n",
      "Epoch 188/300\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.3228 - accuracy: 0.8391 - val_loss: 0.5718 - val_accuracy: 0.7967\n",
      "Epoch 189/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.3227 - accuracy: 0.8411 - val_loss: 0.5698 - val_accuracy: 0.7967\n",
      "Epoch 190/300\n",
      "491/491 [==============================] - 0s 183us/step - loss: 0.3231 - accuracy: 0.8452 - val_loss: 0.5757 - val_accuracy: 0.7886\n",
      "Epoch 191/300\n",
      "491/491 [==============================] - 0s 202us/step - loss: 0.3218 - accuracy: 0.8473 - val_loss: 0.5788 - val_accuracy: 0.7886\n",
      "Epoch 192/300\n",
      "491/491 [==============================] - 0s 213us/step - loss: 0.3217 - accuracy: 0.8411 - val_loss: 0.5779 - val_accuracy: 0.7886\n",
      "Epoch 193/300\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.3217 - accuracy: 0.8411 - val_loss: 0.5802 - val_accuracy: 0.7886\n",
      "Epoch 194/300\n",
      "491/491 [==============================] - 0s 198us/step - loss: 0.3208 - accuracy: 0.8452 - val_loss: 0.5654 - val_accuracy: 0.7886\n",
      "Epoch 195/300\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.3211 - accuracy: 0.8452 - val_loss: 0.5751 - val_accuracy: 0.7724\n",
      "Epoch 196/300\n",
      "491/491 [==============================] - 0s 191us/step - loss: 0.3227 - accuracy: 0.8411 - val_loss: 0.5758 - val_accuracy: 0.7805\n",
      "Epoch 197/300\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.3201 - accuracy: 0.8493 - val_loss: 0.5792 - val_accuracy: 0.7724\n",
      "Epoch 198/300\n",
      "491/491 [==============================] - 0s 190us/step - loss: 0.3221 - accuracy: 0.8493 - val_loss: 0.5780 - val_accuracy: 0.7805\n",
      "Epoch 199/300\n",
      "491/491 [==============================] - 0s 207us/step - loss: 0.3251 - accuracy: 0.8371 - val_loss: 0.5657 - val_accuracy: 0.7886\n",
      "Epoch 200/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3195 - accuracy: 0.8493 - val_loss: 0.5824 - val_accuracy: 0.7967\n",
      "Epoch 201/300\n",
      "491/491 [==============================] - 0s 196us/step - loss: 0.3183 - accuracy: 0.8473 - val_loss: 0.5845 - val_accuracy: 0.7886\n",
      "Epoch 202/300\n",
      "491/491 [==============================] - 0s 210us/step - loss: 0.3188 - accuracy: 0.8391 - val_loss: 0.5833 - val_accuracy: 0.7886\n",
      "Epoch 203/300\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.3183 - accuracy: 0.8432 - val_loss: 0.5876 - val_accuracy: 0.7886\n",
      "Epoch 204/300\n",
      "491/491 [==============================] - 0s 191us/step - loss: 0.3181 - accuracy: 0.8473 - val_loss: 0.5850 - val_accuracy: 0.7805\n",
      "Epoch 205/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3183 - accuracy: 0.8452 - val_loss: 0.5850 - val_accuracy: 0.7886\n",
      "Epoch 206/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.3260 - accuracy: 0.8411 - val_loss: 0.6169 - val_accuracy: 0.7805\n",
      "Epoch 207/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.3187 - accuracy: 0.8493 - val_loss: 0.5902 - val_accuracy: 0.7805\n",
      "Epoch 208/300\n",
      "491/491 [==============================] - 0s 193us/step - loss: 0.3165 - accuracy: 0.8432 - val_loss: 0.5936 - val_accuracy: 0.7805\n",
      "Epoch 209/300\n",
      "491/491 [==============================] - 0s 200us/step - loss: 0.3167 - accuracy: 0.8473 - val_loss: 0.5936 - val_accuracy: 0.7886\n",
      "Epoch 210/300\n",
      "491/491 [==============================] - 0s 197us/step - loss: 0.3163 - accuracy: 0.8452 - val_loss: 0.5944 - val_accuracy: 0.7805\n",
      "Epoch 211/300\n",
      "491/491 [==============================] - 0s 208us/step - loss: 0.3164 - accuracy: 0.8432 - val_loss: 0.5910 - val_accuracy: 0.7805\n",
      "Epoch 212/300\n",
      "491/491 [==============================] - 0s 223us/step - loss: 0.3157 - accuracy: 0.8452 - val_loss: 0.5920 - val_accuracy: 0.7886\n",
      "Epoch 213/300\n",
      "491/491 [==============================] - 0s 207us/step - loss: 0.3167 - accuracy: 0.8473 - val_loss: 0.5901 - val_accuracy: 0.7805\n",
      "Epoch 214/300\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.3156 - accuracy: 0.8432 - val_loss: 0.5904 - val_accuracy: 0.7805\n",
      "Epoch 215/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.3151 - accuracy: 0.8473 - val_loss: 0.5967 - val_accuracy: 0.7805\n",
      "Epoch 216/300\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.3155 - accuracy: 0.8452 - val_loss: 0.5969 - val_accuracy: 0.7724\n",
      "Epoch 217/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.3138 - accuracy: 0.8473 - val_loss: 0.5936 - val_accuracy: 0.7805\n",
      "Epoch 218/300\n",
      "491/491 [==============================] - 0s 191us/step - loss: 0.3144 - accuracy: 0.8411 - val_loss: 0.5958 - val_accuracy: 0.7805\n",
      "Epoch 219/300\n",
      "491/491 [==============================] - 0s 200us/step - loss: 0.3127 - accuracy: 0.8432 - val_loss: 0.5956 - val_accuracy: 0.7724\n",
      "Epoch 220/300\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.3124 - accuracy: 0.8391 - val_loss: 0.5930 - val_accuracy: 0.7805\n",
      "Epoch 221/300\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.3127 - accuracy: 0.8513 - val_loss: 0.5972 - val_accuracy: 0.7724\n",
      "Epoch 222/300\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.3119 - accuracy: 0.8391 - val_loss: 0.5895 - val_accuracy: 0.7805\n",
      "Epoch 223/300\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.3113 - accuracy: 0.8391 - val_loss: 0.6026 - val_accuracy: 0.7805\n",
      "Epoch 224/300\n",
      "491/491 [==============================] - 0s 188us/step - loss: 0.3121 - accuracy: 0.8452 - val_loss: 0.5938 - val_accuracy: 0.7805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.3138 - accuracy: 0.8473 - val_loss: 0.6005 - val_accuracy: 0.7724\n",
      "Epoch 226/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3137 - accuracy: 0.8595 - val_loss: 0.6006 - val_accuracy: 0.7480\n",
      "Epoch 227/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.3106 - accuracy: 0.8493 - val_loss: 0.5993 - val_accuracy: 0.7642\n",
      "Epoch 228/300\n",
      "491/491 [==============================] - 0s 151us/step - loss: 0.3100 - accuracy: 0.8513 - val_loss: 0.5906 - val_accuracy: 0.7724\n",
      "Epoch 229/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3113 - accuracy: 0.8513 - val_loss: 0.5978 - val_accuracy: 0.7724\n",
      "Epoch 230/300\n",
      "491/491 [==============================] - 0s 151us/step - loss: 0.3101 - accuracy: 0.8452 - val_loss: 0.5908 - val_accuracy: 0.7724\n",
      "Epoch 231/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.3104 - accuracy: 0.8473 - val_loss: 0.5956 - val_accuracy: 0.7724\n",
      "Epoch 232/300\n",
      "491/491 [==============================] - 0s 151us/step - loss: 0.3104 - accuracy: 0.8473 - val_loss: 0.5965 - val_accuracy: 0.7724\n",
      "Epoch 233/300\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.3116 - accuracy: 0.8513 - val_loss: 0.5975 - val_accuracy: 0.7805\n",
      "Epoch 234/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3081 - accuracy: 0.8452 - val_loss: 0.5974 - val_accuracy: 0.7805\n",
      "Epoch 235/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3073 - accuracy: 0.8452 - val_loss: 0.6039 - val_accuracy: 0.7805\n",
      "Epoch 236/300\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.3099 - accuracy: 0.8473 - val_loss: 0.6052 - val_accuracy: 0.7805\n",
      "Epoch 237/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3085 - accuracy: 0.8452 - val_loss: 0.6062 - val_accuracy: 0.7805\n",
      "Epoch 238/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3083 - accuracy: 0.8411 - val_loss: 0.6000 - val_accuracy: 0.7805\n",
      "Epoch 239/300\n",
      "491/491 [==============================] - 0s 151us/step - loss: 0.3070 - accuracy: 0.8473 - val_loss: 0.6086 - val_accuracy: 0.7805\n",
      "Epoch 240/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3064 - accuracy: 0.8391 - val_loss: 0.6074 - val_accuracy: 0.7805\n",
      "Epoch 241/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.3051 - accuracy: 0.8534 - val_loss: 0.6044 - val_accuracy: 0.7724\n",
      "Epoch 242/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3058 - accuracy: 0.8452 - val_loss: 0.6096 - val_accuracy: 0.7724\n",
      "Epoch 243/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3053 - accuracy: 0.8513 - val_loss: 0.6001 - val_accuracy: 0.7724\n",
      "Epoch 244/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.3047 - accuracy: 0.8432 - val_loss: 0.6069 - val_accuracy: 0.7724\n",
      "Epoch 245/300\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.3039 - accuracy: 0.8452 - val_loss: 0.6158 - val_accuracy: 0.7724\n",
      "Epoch 246/300\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.3062 - accuracy: 0.8534 - val_loss: 0.6114 - val_accuracy: 0.7561\n",
      "Epoch 247/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3044 - accuracy: 0.8554 - val_loss: 0.6158 - val_accuracy: 0.7398\n",
      "Epoch 248/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3037 - accuracy: 0.8513 - val_loss: 0.6124 - val_accuracy: 0.7642\n",
      "Epoch 249/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3032 - accuracy: 0.8493 - val_loss: 0.6102 - val_accuracy: 0.7805\n",
      "Epoch 250/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3042 - accuracy: 0.8493 - val_loss: 0.6170 - val_accuracy: 0.7724\n",
      "Epoch 251/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3025 - accuracy: 0.8534 - val_loss: 0.6118 - val_accuracy: 0.7805\n",
      "Epoch 252/300\n",
      "491/491 [==============================] - 0s 151us/step - loss: 0.3021 - accuracy: 0.8473 - val_loss: 0.6122 - val_accuracy: 0.7642\n",
      "Epoch 253/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.3013 - accuracy: 0.8554 - val_loss: 0.6241 - val_accuracy: 0.7642\n",
      "Epoch 254/300\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.3005 - accuracy: 0.8513 - val_loss: 0.6170 - val_accuracy: 0.7805\n",
      "Epoch 255/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.3010 - accuracy: 0.8534 - val_loss: 0.6264 - val_accuracy: 0.7805\n",
      "Epoch 256/300\n",
      "491/491 [==============================] - 0s 212us/step - loss: 0.3000 - accuracy: 0.8534 - val_loss: 0.6181 - val_accuracy: 0.7805\n",
      "Epoch 257/300\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.3009 - accuracy: 0.8534 - val_loss: 0.6117 - val_accuracy: 0.7642\n",
      "Epoch 258/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.3005 - accuracy: 0.8534 - val_loss: 0.6198 - val_accuracy: 0.7642\n",
      "Epoch 259/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.2981 - accuracy: 0.8534 - val_loss: 0.6141 - val_accuracy: 0.7724\n",
      "Epoch 260/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.3006 - accuracy: 0.8534 - val_loss: 0.6164 - val_accuracy: 0.7724\n",
      "Epoch 261/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.3000 - accuracy: 0.8534 - val_loss: 0.6200 - val_accuracy: 0.7561\n",
      "Epoch 262/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.2987 - accuracy: 0.8554 - val_loss: 0.6212 - val_accuracy: 0.7480\n",
      "Epoch 263/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.2981 - accuracy: 0.8493 - val_loss: 0.6244 - val_accuracy: 0.7724\n",
      "Epoch 264/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.2982 - accuracy: 0.8513 - val_loss: 0.6321 - val_accuracy: 0.7642\n",
      "Epoch 265/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.2974 - accuracy: 0.8534 - val_loss: 0.6334 - val_accuracy: 0.7480\n",
      "Epoch 266/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.2981 - accuracy: 0.8635 - val_loss: 0.6418 - val_accuracy: 0.7642\n",
      "Epoch 267/300\n",
      "491/491 [==============================] - 0s 151us/step - loss: 0.2970 - accuracy: 0.8615 - val_loss: 0.6153 - val_accuracy: 0.7642\n",
      "Epoch 268/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.2968 - accuracy: 0.8635 - val_loss: 0.6253 - val_accuracy: 0.7642\n",
      "Epoch 269/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.2959 - accuracy: 0.8554 - val_loss: 0.6247 - val_accuracy: 0.7642\n",
      "Epoch 270/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.2958 - accuracy: 0.8534 - val_loss: 0.6308 - val_accuracy: 0.7642\n",
      "Epoch 271/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.2951 - accuracy: 0.8595 - val_loss: 0.6265 - val_accuracy: 0.7642\n",
      "Epoch 272/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.2955 - accuracy: 0.8513 - val_loss: 0.6323 - val_accuracy: 0.7561\n",
      "Epoch 273/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.2951 - accuracy: 0.8534 - val_loss: 0.6314 - val_accuracy: 0.7724\n",
      "Epoch 274/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.2935 - accuracy: 0.8534 - val_loss: 0.6398 - val_accuracy: 0.7561\n",
      "Epoch 275/300\n",
      "491/491 [==============================] - 0s 157us/step - loss: 0.2948 - accuracy: 0.8554 - val_loss: 0.6322 - val_accuracy: 0.7480\n",
      "Epoch 276/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.2961 - accuracy: 0.8615 - val_loss: 0.6203 - val_accuracy: 0.7805\n",
      "Epoch 277/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.2934 - accuracy: 0.8534 - val_loss: 0.6401 - val_accuracy: 0.7480\n",
      "Epoch 278/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.2941 - accuracy: 0.8595 - val_loss: 0.6286 - val_accuracy: 0.7480\n",
      "Epoch 279/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.2935 - accuracy: 0.8554 - val_loss: 0.6351 - val_accuracy: 0.7480\n",
      "Epoch 280/300\n",
      "491/491 [==============================] - 0s 154us/step - loss: 0.2939 - accuracy: 0.8534 - val_loss: 0.6282 - val_accuracy: 0.7642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "491/491 [==============================] - 0s 152us/step - loss: 0.2927 - accuracy: 0.8595 - val_loss: 0.6354 - val_accuracy: 0.7561\n",
      "Epoch 282/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.2933 - accuracy: 0.8595 - val_loss: 0.6367 - val_accuracy: 0.7480\n",
      "Epoch 283/300\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.2930 - accuracy: 0.8574 - val_loss: 0.6388 - val_accuracy: 0.7398\n",
      "Epoch 284/300\n",
      "491/491 [==============================] - 0s 153us/step - loss: 0.2916 - accuracy: 0.8574 - val_loss: 0.6405 - val_accuracy: 0.7561\n",
      "Epoch 285/300\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.2918 - accuracy: 0.8574 - val_loss: 0.6426 - val_accuracy: 0.7480\n",
      "Epoch 286/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.2907 - accuracy: 0.8574 - val_loss: 0.6408 - val_accuracy: 0.7561\n",
      "Epoch 287/300\n",
      "491/491 [==============================] - 0s 156us/step - loss: 0.2933 - accuracy: 0.8554 - val_loss: 0.6418 - val_accuracy: 0.7480\n",
      "Epoch 288/300\n",
      "491/491 [==============================] - 0s 155us/step - loss: 0.2904 - accuracy: 0.8595 - val_loss: 0.6354 - val_accuracy: 0.7398\n",
      "Epoch 289/300\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.2915 - accuracy: 0.8595 - val_loss: 0.6274 - val_accuracy: 0.7561\n",
      "Epoch 290/300\n",
      "491/491 [==============================] - 0s 192us/step - loss: 0.2905 - accuracy: 0.8574 - val_loss: 0.6470 - val_accuracy: 0.7398\n",
      "Epoch 291/300\n",
      "491/491 [==============================] - 0s 202us/step - loss: 0.2887 - accuracy: 0.8615 - val_loss: 0.6334 - val_accuracy: 0.7398\n",
      "Epoch 292/300\n",
      "491/491 [==============================] - 0s 190us/step - loss: 0.2901 - accuracy: 0.8615 - val_loss: 0.6340 - val_accuracy: 0.7561\n",
      "Epoch 293/300\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.2917 - accuracy: 0.8615 - val_loss: 0.6538 - val_accuracy: 0.7398\n",
      "Epoch 294/300\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.2914 - accuracy: 0.8615 - val_loss: 0.6431 - val_accuracy: 0.7317\n",
      "Epoch 295/300\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.2889 - accuracy: 0.8534 - val_loss: 0.6442 - val_accuracy: 0.7398\n",
      "Epoch 296/300\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.2874 - accuracy: 0.8595 - val_loss: 0.6404 - val_accuracy: 0.7398\n",
      "Epoch 297/300\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.2863 - accuracy: 0.8635 - val_loss: 0.6531 - val_accuracy: 0.7398\n",
      "Epoch 298/300\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.2886 - accuracy: 0.8554 - val_loss: 0.6439 - val_accuracy: 0.7480\n",
      "Epoch 299/300\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.2872 - accuracy: 0.8534 - val_loss: 0.6418 - val_accuracy: 0.7561\n",
      "Epoch 300/300\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.2873 - accuracy: 0.8574 - val_loss: 0.6498 - val_accuracy: 0.7642\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=300, batch_size = 10, validation_split=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greatest-currency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 81us/step\n",
      "('accuracy', 70.77922224998474)\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print((model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "completed-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Models Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Models loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-still",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "technological-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "phantom-jesus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                165       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                192       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 588\n",
      "Trainable params: 588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(10, input_dim=X_train.shape[1], activation='relu')) # input layer\n",
    "model2.add(Dense(15, kernel_regularizer=l2(0.01), activation='relu')) # hidden layer \n",
    "model2.add(Dense(12, kernel_regularizer=l2(0.01), activation='relu')) # hidden layer\n",
    "model2.add(Dense(10, kernel_regularizer=l2(0.01), activation='relu')) # hidden layer\n",
    "model2.add(Dense(1, activation='sigmoid')) # output layer\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "primary-finger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 491 samples, validate on 123 samples\n",
      "Epoch 1/800\n",
      "491/491 [==============================] - 1s 2ms/step - loss: 0.9628 - accuracy: 0.6701 - val_loss: 0.8857 - val_accuracy: 0.6992\n",
      "Epoch 2/800\n",
      "491/491 [==============================] - 0s 202us/step - loss: 0.8837 - accuracy: 0.6660 - val_loss: 0.7998 - val_accuracy: 0.6911\n",
      "Epoch 3/800\n",
      "491/491 [==============================] - 0s 187us/step - loss: 0.8211 - accuracy: 0.6782 - val_loss: 0.7343 - val_accuracy: 0.7073\n",
      "Epoch 4/800\n",
      "491/491 [==============================] - 0s 203us/step - loss: 0.7740 - accuracy: 0.6904 - val_loss: 0.6825 - val_accuracy: 0.7561\n",
      "Epoch 5/800\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.7350 - accuracy: 0.7149 - val_loss: 0.6508 - val_accuracy: 0.7805\n",
      "Epoch 6/800\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.7022 - accuracy: 0.7088 - val_loss: 0.6189 - val_accuracy: 0.7886\n",
      "Epoch 7/800\n",
      "491/491 [==============================] - 0s 247us/step - loss: 0.6732 - accuracy: 0.7230 - val_loss: 0.5916 - val_accuracy: 0.7886\n",
      "Epoch 8/800\n",
      "491/491 [==============================] - 0s 261us/step - loss: 0.6506 - accuracy: 0.7291 - val_loss: 0.5703 - val_accuracy: 0.7967\n",
      "Epoch 9/800\n",
      "491/491 [==============================] - 0s 263us/step - loss: 0.6313 - accuracy: 0.7413 - val_loss: 0.5565 - val_accuracy: 0.7967\n",
      "Epoch 10/800\n",
      "491/491 [==============================] - 0s 225us/step - loss: 0.6171 - accuracy: 0.7413 - val_loss: 0.5463 - val_accuracy: 0.7967\n",
      "Epoch 11/800\n",
      "491/491 [==============================] - 0s 206us/step - loss: 0.6005 - accuracy: 0.7515 - val_loss: 0.5288 - val_accuracy: 0.7967\n",
      "Epoch 12/800\n",
      "491/491 [==============================] - 0s 205us/step - loss: 0.5901 - accuracy: 0.7515 - val_loss: 0.5180 - val_accuracy: 0.7967\n",
      "Epoch 13/800\n",
      "491/491 [==============================] - 0s 207us/step - loss: 0.5799 - accuracy: 0.7536 - val_loss: 0.5062 - val_accuracy: 0.8130\n",
      "Epoch 14/800\n",
      "491/491 [==============================] - 0s 226us/step - loss: 0.5726 - accuracy: 0.7597 - val_loss: 0.4959 - val_accuracy: 0.8211\n",
      "Epoch 15/800\n",
      "491/491 [==============================] - 0s 270us/step - loss: 0.5642 - accuracy: 0.7556 - val_loss: 0.4937 - val_accuracy: 0.8293\n",
      "Epoch 16/800\n",
      "491/491 [==============================] - 0s 242us/step - loss: 0.5587 - accuracy: 0.7637 - val_loss: 0.4884 - val_accuracy: 0.8293\n",
      "Epoch 17/800\n",
      "491/491 [==============================] - 0s 283us/step - loss: 0.5534 - accuracy: 0.7556 - val_loss: 0.4861 - val_accuracy: 0.8293\n",
      "Epoch 18/800\n",
      "491/491 [==============================] - 0s 261us/step - loss: 0.5507 - accuracy: 0.7637 - val_loss: 0.4839 - val_accuracy: 0.8211\n",
      "Epoch 19/800\n",
      "491/491 [==============================] - 0s 229us/step - loss: 0.5446 - accuracy: 0.7699 - val_loss: 0.4763 - val_accuracy: 0.8293\n",
      "Epoch 20/800\n",
      "491/491 [==============================] - 0s 208us/step - loss: 0.5422 - accuracy: 0.7617 - val_loss: 0.4747 - val_accuracy: 0.8374\n",
      "Epoch 21/800\n",
      "491/491 [==============================] - 0s 231us/step - loss: 0.5385 - accuracy: 0.7719 - val_loss: 0.4700 - val_accuracy: 0.8455\n",
      "Epoch 22/800\n",
      "491/491 [==============================] - 0s 271us/step - loss: 0.5345 - accuracy: 0.7780 - val_loss: 0.4630 - val_accuracy: 0.8455\n",
      "Epoch 23/800\n",
      "491/491 [==============================] - 0s 248us/step - loss: 0.5334 - accuracy: 0.7678 - val_loss: 0.4664 - val_accuracy: 0.7967\n",
      "Epoch 24/800\n",
      "491/491 [==============================] - 0s 196us/step - loss: 0.5275 - accuracy: 0.7780 - val_loss: 0.4627 - val_accuracy: 0.8211\n",
      "Epoch 25/800\n",
      "491/491 [==============================] - 0s 211us/step - loss: 0.5248 - accuracy: 0.7739 - val_loss: 0.4620 - val_accuracy: 0.8049\n",
      "Epoch 26/800\n",
      "491/491 [==============================] - 0s 218us/step - loss: 0.5231 - accuracy: 0.7780 - val_loss: 0.4594 - val_accuracy: 0.8049\n",
      "Epoch 27/800\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.5232 - accuracy: 0.7739 - val_loss: 0.4562 - val_accuracy: 0.8293\n",
      "Epoch 28/800\n",
      "491/491 [==============================] - 0s 224us/step - loss: 0.5185 - accuracy: 0.7719 - val_loss: 0.4583 - val_accuracy: 0.7967\n",
      "Epoch 29/800\n",
      "491/491 [==============================] - 0s 221us/step - loss: 0.5167 - accuracy: 0.7841 - val_loss: 0.4530 - val_accuracy: 0.8130\n",
      "Epoch 30/800\n",
      "491/491 [==============================] - 0s 214us/step - loss: 0.5157 - accuracy: 0.7800 - val_loss: 0.4565 - val_accuracy: 0.7967\n",
      "Epoch 31/800\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.5137 - accuracy: 0.7821 - val_loss: 0.4550 - val_accuracy: 0.8130\n",
      "Epoch 32/800\n",
      "491/491 [==============================] - 0s 211us/step - loss: 0.5119 - accuracy: 0.7739 - val_loss: 0.4523 - val_accuracy: 0.8130\n",
      "Epoch 33/800\n",
      "491/491 [==============================] - 0s 206us/step - loss: 0.5113 - accuracy: 0.7902 - val_loss: 0.4448 - val_accuracy: 0.8374\n",
      "Epoch 34/800\n",
      "491/491 [==============================] - 0s 222us/step - loss: 0.5082 - accuracy: 0.7739 - val_loss: 0.4446 - val_accuracy: 0.8293\n",
      "Epoch 35/800\n",
      "491/491 [==============================] - 0s 226us/step - loss: 0.5061 - accuracy: 0.7780 - val_loss: 0.4545 - val_accuracy: 0.8049\n",
      "Epoch 36/800\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.5110 - accuracy: 0.7760 - val_loss: 0.4494 - val_accuracy: 0.8211\n",
      "Epoch 37/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.5058 - accuracy: 0.7719 - val_loss: 0.4405 - val_accuracy: 0.8211\n",
      "Epoch 38/800\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.5030 - accuracy: 0.7780 - val_loss: 0.4481 - val_accuracy: 0.8211\n",
      "Epoch 39/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.5011 - accuracy: 0.7739 - val_loss: 0.4417 - val_accuracy: 0.8293\n",
      "Epoch 40/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4993 - accuracy: 0.7739 - val_loss: 0.4394 - val_accuracy: 0.8455\n",
      "Epoch 41/800\n",
      "491/491 [==============================] - 0s 181us/step - loss: 0.4985 - accuracy: 0.7800 - val_loss: 0.4397 - val_accuracy: 0.8293\n",
      "Epoch 42/800\n",
      "491/491 [==============================] - 0s 199us/step - loss: 0.4991 - accuracy: 0.7821 - val_loss: 0.4378 - val_accuracy: 0.8293\n",
      "Epoch 43/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4966 - accuracy: 0.7800 - val_loss: 0.4381 - val_accuracy: 0.8374\n",
      "Epoch 44/800\n",
      "491/491 [==============================] - 0s 212us/step - loss: 0.4983 - accuracy: 0.7739 - val_loss: 0.4386 - val_accuracy: 0.8211\n",
      "Epoch 45/800\n",
      "491/491 [==============================] - 0s 225us/step - loss: 0.4950 - accuracy: 0.7800 - val_loss: 0.4381 - val_accuracy: 0.8293\n",
      "Epoch 46/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4928 - accuracy: 0.7739 - val_loss: 0.4397 - val_accuracy: 0.8130\n",
      "Epoch 47/800\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.4923 - accuracy: 0.7739 - val_loss: 0.4407 - val_accuracy: 0.8049\n",
      "Epoch 48/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4916 - accuracy: 0.7780 - val_loss: 0.4376 - val_accuracy: 0.8130\n",
      "Epoch 49/800\n",
      "491/491 [==============================] - 0s 197us/step - loss: 0.4927 - accuracy: 0.7780 - val_loss: 0.4424 - val_accuracy: 0.8130\n",
      "Epoch 50/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4915 - accuracy: 0.7800 - val_loss: 0.4388 - val_accuracy: 0.8130\n",
      "Epoch 51/800\n",
      "491/491 [==============================] - 0s 191us/step - loss: 0.4907 - accuracy: 0.7719 - val_loss: 0.4374 - val_accuracy: 0.8049\n",
      "Epoch 52/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4895 - accuracy: 0.7760 - val_loss: 0.4344 - val_accuracy: 0.8130\n",
      "Epoch 53/800\n",
      "491/491 [==============================] - 0s 192us/step - loss: 0.4895 - accuracy: 0.7841 - val_loss: 0.4400 - val_accuracy: 0.8049\n",
      "Epoch 54/800\n",
      "491/491 [==============================] - 0s 183us/step - loss: 0.4875 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8374\n",
      "Epoch 55/800\n",
      "491/491 [==============================] - 0s 230us/step - loss: 0.4860 - accuracy: 0.7780 - val_loss: 0.4349 - val_accuracy: 0.8049\n",
      "Epoch 56/800\n",
      "491/491 [==============================] - 0s 210us/step - loss: 0.4851 - accuracy: 0.7760 - val_loss: 0.4334 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/800\n",
      "491/491 [==============================] - 0s 195us/step - loss: 0.4861 - accuracy: 0.7780 - val_loss: 0.4324 - val_accuracy: 0.8130\n",
      "Epoch 58/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4840 - accuracy: 0.7882 - val_loss: 0.4357 - val_accuracy: 0.8049\n",
      "Epoch 59/800\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.4846 - accuracy: 0.7800 - val_loss: 0.4358 - val_accuracy: 0.8049\n",
      "Epoch 60/800\n",
      "491/491 [==============================] - 0s 236us/step - loss: 0.4841 - accuracy: 0.7841 - val_loss: 0.4348 - val_accuracy: 0.8049\n",
      "Epoch 61/800\n",
      "491/491 [==============================] - 0s 247us/step - loss: 0.4816 - accuracy: 0.7780 - val_loss: 0.4349 - val_accuracy: 0.8049\n",
      "Epoch 62/800\n",
      "491/491 [==============================] - 0s 196us/step - loss: 0.4840 - accuracy: 0.7760 - val_loss: 0.4389 - val_accuracy: 0.8049\n",
      "Epoch 63/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4846 - accuracy: 0.7821 - val_loss: 0.4388 - val_accuracy: 0.8049\n",
      "Epoch 64/800\n",
      "491/491 [==============================] - 0s 196us/step - loss: 0.4805 - accuracy: 0.7841 - val_loss: 0.4326 - val_accuracy: 0.8211\n",
      "Epoch 65/800\n",
      "491/491 [==============================] - 0s 199us/step - loss: 0.4839 - accuracy: 0.7760 - val_loss: 0.4411 - val_accuracy: 0.8049\n",
      "Epoch 66/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4783 - accuracy: 0.7862 - val_loss: 0.4344 - val_accuracy: 0.8130\n",
      "Epoch 67/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4820 - accuracy: 0.7943 - val_loss: 0.4336 - val_accuracy: 0.8211\n",
      "Epoch 68/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4752 - accuracy: 0.7902 - val_loss: 0.4335 - val_accuracy: 0.8211\n",
      "Epoch 69/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4743 - accuracy: 0.7821 - val_loss: 0.4334 - val_accuracy: 0.8049\n",
      "Epoch 70/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4740 - accuracy: 0.7800 - val_loss: 0.4336 - val_accuracy: 0.8049\n",
      "Epoch 71/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4744 - accuracy: 0.7862 - val_loss: 0.4339 - val_accuracy: 0.8049\n",
      "Epoch 72/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4742 - accuracy: 0.7841 - val_loss: 0.4340 - val_accuracy: 0.8049\n",
      "Epoch 73/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4741 - accuracy: 0.7841 - val_loss: 0.4338 - val_accuracy: 0.8049\n",
      "Epoch 74/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4740 - accuracy: 0.7780 - val_loss: 0.4336 - val_accuracy: 0.8049\n",
      "Epoch 75/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4737 - accuracy: 0.7800 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 76/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4736 - accuracy: 0.7800 - val_loss: 0.4335 - val_accuracy: 0.8049\n",
      "Epoch 77/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4737 - accuracy: 0.7780 - val_loss: 0.4329 - val_accuracy: 0.8049\n",
      "Epoch 78/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 79/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 80/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 81/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 82/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 83/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 84/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 85/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 86/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 87/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 88/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4731 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 89/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 90/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 91/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 92/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 93/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 94/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 95/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 96/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 97/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 98/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 99/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 100/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 101/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 102/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4730 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 103/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4729 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 104/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 105/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 106/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 107/800\n",
      "491/491 [==============================] - 0s 212us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 108/800\n",
      "491/491 [==============================] - 0s 236us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 109/800\n",
      "491/491 [==============================] - 0s 254us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 110/800\n",
      "491/491 [==============================] - 0s 195us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 111/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 112/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 113/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 204us/step - loss: 0.4729 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 114/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 115/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 116/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4729 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 117/800\n",
      "491/491 [==============================] - 0s 203us/step - loss: 0.4730 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 118/800\n",
      "491/491 [==============================] - 0s 240us/step - loss: 0.4729 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 119/800\n",
      "491/491 [==============================] - 0s 248us/step - loss: 0.4728 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 120/800\n",
      "491/491 [==============================] - 0s 243us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 121/800\n",
      "491/491 [==============================] - 0s 247us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 122/800\n",
      "491/491 [==============================] - 0s 269us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 123/800\n",
      "491/491 [==============================] - 0s 202us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 124/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 125/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4728 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 126/800\n",
      "491/491 [==============================] - 0s 213us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 127/800\n",
      "491/491 [==============================] - 0s 225us/step - loss: 0.4728 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 128/800\n",
      "491/491 [==============================] - 0s 181us/step - loss: 0.4728 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 129/800\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 130/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4728 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 131/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 132/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 133/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 134/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4727 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 135/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4727 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 136/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4728 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 137/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4727 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 138/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 139/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 140/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 141/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4727 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 142/800\n",
      "491/491 [==============================] - 0s 191us/step - loss: 0.4727 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 143/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4727 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 144/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 145/800\n",
      "491/491 [==============================] - 0s 250us/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 146/800\n",
      "491/491 [==============================] - 0s 256us/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 147/800\n",
      "491/491 [==============================] - 0s 230us/step - loss: 0.4727 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 148/800\n",
      "491/491 [==============================] - 0s 221us/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 149/800\n",
      "491/491 [==============================] - 0s 246us/step - loss: 0.4727 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 150/800\n",
      "491/491 [==============================] - 0s 231us/step - loss: 0.4727 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 151/800\n",
      "491/491 [==============================] - 0s 181us/step - loss: 0.4726 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 152/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4726 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 153/800\n",
      "491/491 [==============================] - 0s 206us/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 154/800\n",
      "491/491 [==============================] - 0s 261us/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 155/800\n",
      "491/491 [==============================] - 0s 262us/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 156/800\n",
      "491/491 [==============================] - 0s 187us/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 157/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4727 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 158/800\n",
      "491/491 [==============================] - 0s 193us/step - loss: 0.4726 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 159/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 160/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4726 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 161/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 162/800\n",
      "491/491 [==============================] - 0s 266us/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 163/800\n",
      "491/491 [==============================] - 0s 225us/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 164/800\n",
      "491/491 [==============================] - 0s 209us/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 165/800\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.4726 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 166/800\n",
      "491/491 [==============================] - 0s 181us/step - loss: 0.4726 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 167/800\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 168/800\n",
      "491/491 [==============================] - 0s 204us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/800\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 170/800\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.4726 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 171/800\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.4725 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 172/800\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 173/800\n",
      "491/491 [==============================] - 0s 201us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 174/800\n",
      "491/491 [==============================] - 0s 259us/step - loss: 0.4725 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 175/800\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.4725 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 176/800\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 177/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 178/800\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 179/800\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 180/800\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.4725 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 181/800\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 182/800\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.4725 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 183/800\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4725 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 184/800\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.4724 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 185/800\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.4725 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 186/800\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 187/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4724 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 188/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 189/800\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 190/800\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.4724 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 191/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 192/800\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 193/800\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 194/800\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.4724 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 195/800\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 196/800\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 197/800\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 198/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 199/800\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 200/800\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 201/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 202/800\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 203/800\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 204/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4724 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 205/800\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.4723 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 206/800\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 207/800\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 208/800\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 209/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 210/800\n",
      "491/491 [==============================] - 0s 161us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 211/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 212/800\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 213/800\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 214/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 215/800\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 216/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4723 - accuracy: 0.7780 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 217/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 218/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 219/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 220/800\n",
      "491/491 [==============================] - 0s 159us/step - loss: 0.4722 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 221/800\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 222/800\n",
      "491/491 [==============================] - 0s 162us/step - loss: 0.4722 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 223/800\n",
      "491/491 [==============================] - 0s 160us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 224/800\n",
      "491/491 [==============================] - 0s 158us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/800\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 226/800\n",
      "491/491 [==============================] - 0s 269us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 227/800\n",
      "491/491 [==============================] - 0s 222us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 228/800\n",
      "491/491 [==============================] - 0s 231us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 229/800\n",
      "491/491 [==============================] - 0s 233us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 230/800\n",
      "491/491 [==============================] - 0s 334us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 231/800\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 232/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 233/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 234/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 235/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 236/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 237/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 238/800\n",
      "491/491 [==============================] - 0s 180us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 239/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 240/800\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.4721 - accuracy: 0.7821 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 241/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 242/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 243/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4721 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 244/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 245/800\n",
      "491/491 [==============================] - 0s 189us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 246/800\n",
      "491/491 [==============================] - 0s 226us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 247/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 248/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4721 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 249/800\n",
      "491/491 [==============================] - 0s 203us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 250/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 251/800\n",
      "491/491 [==============================] - 0s 196us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 252/800\n",
      "491/491 [==============================] - 0s 437us/step - loss: 0.4720 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 253/800\n",
      "491/491 [==============================] - 0s 251us/step - loss: 0.4720 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 254/800\n",
      "491/491 [==============================] - 0s 231us/step - loss: 0.4720 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 255/800\n",
      "491/491 [==============================] - 0s 180us/step - loss: 0.4721 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 256/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4720 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 257/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4720 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 258/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4720 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 259/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4720 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 260/800\n",
      "491/491 [==============================] - 0s 212us/step - loss: 0.4720 - accuracy: 0.7821 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 261/800\n",
      "491/491 [==============================] - 0s 234us/step - loss: 0.4720 - accuracy: 0.7780 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 262/800\n",
      "491/491 [==============================] - 0s 221us/step - loss: 0.4720 - accuracy: 0.7821 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 263/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4720 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 264/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4720 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 265/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4720 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 266/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4720 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 267/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4719 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 268/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4720 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 269/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4720 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 270/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4720 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 271/800\n",
      "491/491 [==============================] - 0s 221us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 272/800\n",
      "491/491 [==============================] - 0s 232us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 273/800\n",
      "491/491 [==============================] - 0s 191us/step - loss: 0.4719 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 274/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4719 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 275/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 276/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4719 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 277/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 278/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 279/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 280/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 282/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 283/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4719 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 284/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4719 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 285/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 286/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4719 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 287/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4719 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 288/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4718 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 289/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 290/800\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 291/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4718 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 292/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4718 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 293/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4719 - accuracy: 0.7800 - val_loss: 0.4329 - val_accuracy: 0.8049\n",
      "Epoch 294/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4718 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 295/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 296/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4718 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 297/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 298/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4718 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 299/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 300/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 301/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4718 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 302/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 303/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4718 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 304/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 305/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 306/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 307/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4717 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 308/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 309/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4717 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 310/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 311/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 312/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 313/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4717 - accuracy: 0.7821 - val_loss: 0.4329 - val_accuracy: 0.8049\n",
      "Epoch 314/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 315/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 316/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 317/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4717 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 318/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 319/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 320/800\n",
      "491/491 [==============================] - 0s 206us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 321/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 322/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 323/800\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.4717 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 324/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 325/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 326/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 327/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 328/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 329/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 330/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4717 - accuracy: 0.7800 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 331/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 332/800\n",
      "491/491 [==============================] - 0s 181us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 333/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 334/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 335/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 336/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 338/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 339/800\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4716 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 340/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 341/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 342/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 343/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 344/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 345/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 346/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 347/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 348/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 349/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 350/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 351/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 352/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 353/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 354/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 355/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 356/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 357/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 358/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 359/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4715 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 360/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 361/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 362/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 363/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4714 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 364/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 365/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 366/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 367/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 368/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 369/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 370/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 371/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 372/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 373/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 374/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 375/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 376/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4714 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 377/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 378/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 379/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 380/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 381/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 382/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 383/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 384/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 385/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 386/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 387/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 388/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 389/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 390/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 391/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 392/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 394/800\n",
      "491/491 [==============================] - 0s 180us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 395/800\n",
      "491/491 [==============================] - 0s 210us/step - loss: 0.4713 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 396/800\n",
      "491/491 [==============================] - 0s 222us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 397/800\n",
      "491/491 [==============================] - 0s 239us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 398/800\n",
      "491/491 [==============================] - 0s 227us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 399/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 400/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 401/800\n",
      "491/491 [==============================] - 0s 219us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 402/800\n",
      "491/491 [==============================] - 0s 232us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 403/800\n",
      "491/491 [==============================] - 0s 203us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 404/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 405/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 406/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 407/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 408/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 409/800\n",
      "491/491 [==============================] - 0s 181us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 410/800\n",
      "491/491 [==============================] - 0s 181us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 411/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 412/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 413/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 414/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 415/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 416/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 417/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4712 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 418/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4711 - accuracy: 0.7862 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 419/800\n",
      "491/491 [==============================] - 0s 179us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 420/800\n",
      "491/491 [==============================] - 0s 198us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 421/800\n",
      "491/491 [==============================] - 0s 235us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 422/800\n",
      "491/491 [==============================] - 0s 253us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 423/800\n",
      "491/491 [==============================] - 0s 233us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 424/800\n",
      "491/491 [==============================] - 0s 201us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 425/800\n",
      "491/491 [==============================] - 0s 180us/step - loss: 0.4711 - accuracy: 0.7862 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 426/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 427/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 428/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 429/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 430/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 431/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4711 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 432/800\n",
      "491/491 [==============================] - 0s 187us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 433/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4710 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 434/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 435/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 436/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 437/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 438/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 439/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 440/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 441/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4710 - accuracy: 0.7862 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 442/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 443/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 444/800\n",
      "491/491 [==============================] - 0s 201us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 445/800\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 446/800\n",
      "491/491 [==============================] - 0s 223us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 447/800\n",
      "491/491 [==============================] - 0s 208us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 448/800\n",
      "491/491 [==============================] - 0s 212us/step - loss: 0.4710 - accuracy: 0.7821 - val_loss: 0.4330 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/800\n",
      "491/491 [==============================] - 0s 201us/step - loss: 0.4710 - accuracy: 0.7862 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 450/800\n",
      "491/491 [==============================] - 0s 194us/step - loss: 0.4710 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 451/800\n",
      "491/491 [==============================] - 0s 210us/step - loss: 0.4710 - accuracy: 0.7862 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 452/800\n",
      "491/491 [==============================] - 0s 211us/step - loss: 0.4709 - accuracy: 0.7862 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 453/800\n",
      "491/491 [==============================] - 0s 213us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 454/800\n",
      "491/491 [==============================] - 0s 229us/step - loss: 0.4709 - accuracy: 0.7862 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 455/800\n",
      "491/491 [==============================] - 0s 222us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 456/800\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 457/800\n",
      "491/491 [==============================] - 0s 214us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 458/800\n",
      "491/491 [==============================] - 0s 214us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 459/800\n",
      "491/491 [==============================] - 0s 216us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 460/800\n",
      "491/491 [==============================] - 0s 222us/step - loss: 0.4709 - accuracy: 0.7862 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 461/800\n",
      "491/491 [==============================] - 0s 225us/step - loss: 0.4709 - accuracy: 0.7862 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 462/800\n",
      "491/491 [==============================] - 0s 226us/step - loss: 0.4709 - accuracy: 0.7821 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 463/800\n",
      "491/491 [==============================] - 0s 228us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 464/800\n",
      "491/491 [==============================] - 0s 247us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 465/800\n",
      "491/491 [==============================] - 0s 233us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 466/800\n",
      "491/491 [==============================] - 0s 244us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 467/800\n",
      "491/491 [==============================] - 0s 257us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 468/800\n",
      "491/491 [==============================] - 0s 244us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 469/800\n",
      "491/491 [==============================] - 0s 227us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 470/800\n",
      "491/491 [==============================] - 0s 214us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 471/800\n",
      "491/491 [==============================] - 0s 211us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 472/800\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 473/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 474/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 475/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 476/800\n",
      "491/491 [==============================] - 0s 208us/step - loss: 0.4709 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 477/800\n",
      "491/491 [==============================] - 0s 216us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 478/800\n",
      "491/491 [==============================] - 0s 196us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 479/800\n",
      "491/491 [==============================] - 0s 205us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 480/800\n",
      "491/491 [==============================] - 0s 225us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 481/800\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 482/800\n",
      "491/491 [==============================] - 0s 207us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 483/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 484/800\n",
      "491/491 [==============================] - 0s 238us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 485/800\n",
      "491/491 [==============================] - 0s 214us/step - loss: 0.4708 - accuracy: 0.7862 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 486/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 487/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 488/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 489/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 490/800\n",
      "491/491 [==============================] - 0s 219us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 491/800\n",
      "491/491 [==============================] - 0s 228us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 492/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 493/800\n",
      "491/491 [==============================] - 0s 209us/step - loss: 0.4707 - accuracy: 0.7862 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 494/800\n",
      "491/491 [==============================] - 0s 207us/step - loss: 0.4708 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 495/800\n",
      "491/491 [==============================] - 0s 194us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 496/800\n",
      "491/491 [==============================] - 0s 207us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 497/800\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 498/800\n",
      "491/491 [==============================] - 0s 195us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 499/800\n",
      "491/491 [==============================] - 0s 229us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 500/800\n",
      "491/491 [==============================] - 0s 207us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 501/800\n",
      "491/491 [==============================] - 0s 186us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 502/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 503/800\n",
      "491/491 [==============================] - 0s 185us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 504/800\n",
      "491/491 [==============================] - 0s 209us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/800\n",
      "491/491 [==============================] - 0s 196us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 506/800\n",
      "491/491 [==============================] - 0s 205us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 507/800\n",
      "491/491 [==============================] - 0s 189us/step - loss: 0.4707 - accuracy: 0.7862 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 508/800\n",
      "491/491 [==============================] - 0s 192us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 509/800\n",
      "491/491 [==============================] - 0s 205us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 510/800\n",
      "491/491 [==============================] - 0s 187us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 511/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 512/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4707 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 513/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 514/800\n",
      "491/491 [==============================] - 0s 213us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 515/800\n",
      "491/491 [==============================] - 0s 191us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 516/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 517/800\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 518/800\n",
      "491/491 [==============================] - 0s 186us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 519/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 520/800\n",
      "491/491 [==============================] - 0s 189us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 521/800\n",
      "491/491 [==============================] - 0s 213us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 522/800\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 523/800\n",
      "491/491 [==============================] - 0s 181us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 524/800\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 525/800\n",
      "491/491 [==============================] - 0s 179us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 526/800\n",
      "491/491 [==============================] - 0s 203us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 527/800\n",
      "491/491 [==============================] - 0s 183us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 528/800\n",
      "491/491 [==============================] - 0s 202us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 529/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 530/800\n",
      "491/491 [==============================] - 0s 206us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 531/800\n",
      "491/491 [==============================] - 0s 220us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 532/800\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.4706 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 533/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 534/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 535/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 536/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 537/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 538/800\n",
      "491/491 [==============================] - 0s 218us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 539/800\n",
      "491/491 [==============================] - 0s 242us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 540/800\n",
      "491/491 [==============================] - 0s 250us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 541/800\n",
      "491/491 [==============================] - 0s 205us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 542/800\n",
      "491/491 [==============================] - 0s 202us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 543/800\n",
      "491/491 [==============================] - 0s 189us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 544/800\n",
      "491/491 [==============================] - 0s 188us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 545/800\n",
      "491/491 [==============================] - 0s 210us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 546/800\n",
      "491/491 [==============================] - 0s 239us/step - loss: 0.4705 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 547/800\n",
      "491/491 [==============================] - 0s 210us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 548/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 549/800\n",
      "491/491 [==============================] - 0s 198us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 550/800\n",
      "491/491 [==============================] - 0s 202us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 551/800\n",
      "491/491 [==============================] - 0s 204us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 552/800\n",
      "491/491 [==============================] - 0s 222us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 553/800\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 554/800\n",
      "491/491 [==============================] - 0s 227us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 555/800\n",
      "491/491 [==============================] - 0s 179us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 556/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 557/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 558/800\n",
      "491/491 [==============================] - 0s 195us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 559/800\n",
      "491/491 [==============================] - 0s 220us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 560/800\n",
      "491/491 [==============================] - 0s 251us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/800\n",
      "491/491 [==============================] - 0s 215us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 562/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 563/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 564/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 565/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4330 - val_accuracy: 0.8049\n",
      "Epoch 566/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 567/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4704 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 568/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 569/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 570/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 571/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 572/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 573/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 574/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 575/800\n",
      "491/491 [==============================] - 0s 188us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 576/800\n",
      "491/491 [==============================] - 0s 213us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 577/800\n",
      "491/491 [==============================] - 0s 206us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 578/800\n",
      "491/491 [==============================] - 0s 226us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 579/800\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 580/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 581/800\n",
      "491/491 [==============================] - 0s 213us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 582/800\n",
      "491/491 [==============================] - 0s 208us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 583/800\n",
      "491/491 [==============================] - 0s 203us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 584/800\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 585/800\n",
      "491/491 [==============================] - 0s 183us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 586/800\n",
      "491/491 [==============================] - 0s 202us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 587/800\n",
      "491/491 [==============================] - 0s 201us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 588/800\n",
      "491/491 [==============================] - 0s 224us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 589/800\n",
      "491/491 [==============================] - 0s 209us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 590/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 591/800\n",
      "491/491 [==============================] - 0s 179us/step - loss: 0.4703 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 592/800\n",
      "491/491 [==============================] - 0s 186us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 593/800\n",
      "491/491 [==============================] - 0s 220us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 594/800\n",
      "491/491 [==============================] - 0s 206us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 595/800\n",
      "491/491 [==============================] - 0s 189us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 596/800\n",
      "491/491 [==============================] - 0s 210us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 597/800\n",
      "491/491 [==============================] - 0s 217us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 598/800\n",
      "491/491 [==============================] - 0s 214us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 599/800\n",
      "491/491 [==============================] - 0s 218us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 600/800\n",
      "491/491 [==============================] - 0s 196us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 601/800\n",
      "491/491 [==============================] - 0s 195us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 602/800\n",
      "491/491 [==============================] - 0s 185us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 603/800\n",
      "491/491 [==============================] - 0s 188us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 604/800\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 605/800\n",
      "491/491 [==============================] - 0s 183us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 606/800\n",
      "491/491 [==============================] - 0s 188us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 607/800\n",
      "491/491 [==============================] - 0s 180us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 608/800\n",
      "491/491 [==============================] - 0s 192us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 609/800\n",
      "491/491 [==============================] - 0s 178us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 610/800\n",
      "491/491 [==============================] - 0s 184us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 611/800\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 612/800\n",
      "491/491 [==============================] - 0s 185us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 613/800\n",
      "491/491 [==============================] - 0s 188us/step - loss: 0.4702 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 614/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 615/800\n",
      "491/491 [==============================] - 0s 185us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 616/800\n",
      "491/491 [==============================] - 0s 183us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 618/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 619/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 620/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 621/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 622/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 623/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 624/800\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 625/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 626/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 627/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 628/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 629/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 630/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 631/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 632/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 633/800\n",
      "491/491 [==============================] - 0s 163us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 634/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 635/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 636/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 637/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 638/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 639/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 640/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 641/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 642/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 643/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 644/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 645/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 646/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 647/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 648/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 649/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 650/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 651/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4700 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 652/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 653/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 654/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 655/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 656/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 657/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 658/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 659/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 660/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 661/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 662/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 663/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 664/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 665/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4699 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 666/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 667/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 668/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 669/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 670/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 671/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 672/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 674/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 675/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 676/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 677/800\n",
      "491/491 [==============================] - 0s 164us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 678/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 679/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 680/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 681/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 682/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 683/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 684/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 685/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 686/800\n",
      "491/491 [==============================] - 0s 182us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 687/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 688/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4698 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 689/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 690/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 691/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 692/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 693/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 694/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 695/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 696/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 697/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 698/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 699/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 700/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 701/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 702/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 703/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 704/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4697 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 705/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 706/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 707/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 708/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 709/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 710/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 711/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 712/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 713/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 714/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 715/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 716/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 717/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4331 - val_accuracy: 0.8049\n",
      "Epoch 718/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 719/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 720/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 721/800\n",
      "491/491 [==============================] - 0s 187us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 722/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 723/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 724/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4696 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 725/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 726/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 727/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 728/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 730/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 731/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 732/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 733/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 734/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 735/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 736/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 737/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 738/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 739/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 740/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 741/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 742/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 743/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 744/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 745/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 746/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 747/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 748/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 749/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 750/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 751/800\n",
      "491/491 [==============================] - 0s 168us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 752/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 753/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 754/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4695 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 755/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 756/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 757/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 758/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 759/800\n",
      "491/491 [==============================] - 0s 166us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 760/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 761/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 762/800\n",
      "491/491 [==============================] - 0s 175us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 763/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 764/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 765/800\n",
      "491/491 [==============================] - 0s 177us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 766/800\n",
      "491/491 [==============================] - 0s 176us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 767/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 768/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 769/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 770/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 771/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 772/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 773/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 774/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 775/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 776/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 777/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 778/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 779/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 780/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 781/800\n",
      "491/491 [==============================] - 0s 167us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 782/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 783/800\n",
      "491/491 [==============================] - 0s 172us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 784/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 786/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 787/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 788/800\n",
      "491/491 [==============================] - 0s 173us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 789/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 790/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4693 - accuracy: 0.7862 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 791/800\n",
      "491/491 [==============================] - 0s 169us/step - loss: 0.4693 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 792/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 793/800\n",
      "491/491 [==============================] - 0s 165us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 794/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 795/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4333 - val_accuracy: 0.8049\n",
      "Epoch 796/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 797/800\n",
      "491/491 [==============================] - 0s 174us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 798/800\n",
      "491/491 [==============================] - 0s 170us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 799/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n",
      "Epoch 800/800\n",
      "491/491 [==============================] - 0s 171us/step - loss: 0.4692 - accuracy: 0.7841 - val_loss: 0.4332 - val_accuracy: 0.8049\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', min_lr=0.00001)\n",
    "history2 = model2.fit(X_train, y_train, batch_size=12, epochs=800, callbacks=[reduce_lr], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "martial-marine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 40us/step\n",
      "('accuracy', 77.92207598686218)\n"
     ]
    }
   ],
   "source": [
    "scores = model2.evaluate(X_test, y_test)\n",
    "print((model2.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "italian-munich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('Models Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Models loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-master",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-assist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-presentation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-evidence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-transcription",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-recruitment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-invalid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-barrel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-dietary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
